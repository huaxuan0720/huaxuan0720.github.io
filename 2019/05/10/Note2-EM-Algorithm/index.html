<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
    <meta charset="utf-8">
<title>EM算法 - Welcome to My Blogs</title>
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">



    <meta name="description" content="前言   EM算法是一种可以求解含有隐变量的迭代算法，当我们在实际过程中收集数据的时候，并不一定会收集全部的有效信息。比如，当我们想统计全校学生的身高分布的时候，可以将全校学生的身高看作是一个正态分布，但是毕竟男生和女生之间身高的分布还是有些不同的，但是万一我们没有对性别信息进行统计，而只是统计了身高信息的话，求得的概率分布的参数肯定会有较大的误差，这个时候，我们就需要将每一个样本的性别分布也考">
<meta name="keywords" content="机器学习,EM算法">
<meta property="og:type" content="article">
<meta property="og:title" content="EM算法">
<meta property="og:url" content="http://huaxuan0720.github.io/2019/05/10/Note2-EM-Algorithm/index.html">
<meta property="og:site_name" content="Welcome to My Blogs">
<meta property="og:description" content="前言   EM算法是一种可以求解含有隐变量的迭代算法，当我们在实际过程中收集数据的时候，并不一定会收集全部的有效信息。比如，当我们想统计全校学生的身高分布的时候，可以将全校学生的身高看作是一个正态分布，但是毕竟男生和女生之间身高的分布还是有些不同的，但是万一我们没有对性别信息进行统计，而只是统计了身高信息的话，求得的概率分布的参数肯定会有较大的误差，这个时候，我们就需要将每一个样本的性别分布也考">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://huaxuan0720.github.io/gallery/MachineLearning.jpg">
<meta property="og:updated_time" content="2019-06-03T07:34:31.751Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="EM算法">
<meta name="twitter:description" content="前言   EM算法是一种可以求解含有隐变量的迭代算法，当我们在实际过程中收集数据的时候，并不一定会收集全部的有效信息。比如，当我们想统计全校学生的身高分布的时候，可以将全校学生的身高看作是一个正态分布，但是毕竟男生和女生之间身高的分布还是有些不同的，但是万一我们没有对性别信息进行统计，而只是统计了身高信息的话，求得的概率分布的参数肯定会有较大的误差，这个时候，我们就需要将每一个样本的性别分布也考">
<meta name="twitter:image" content="http://huaxuan0720.github.io/gallery/MachineLearning.jpg">







<link rel="icon" href="/images/favicon.svg">


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.7.2/css/bulma.css">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.4.1/css/all.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:400,600|Source+Code+Pro">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/github-gist.css">


    
    
    
    <style>body>.footer,body>.navbar,body>.section{opacity:0}</style>
    

    
    
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css">
    

    
    

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.css">


    
    
    
    

<link rel="stylesheet" href="/css/back-to-top.css">


    
    

    
    
    
    

    
    
<link rel="stylesheet" href="/css/progressbar.css">
<script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>

    
    
    

    
    
    
        <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    

    


<link rel="stylesheet" href="/css/style.css">
</head>
<body class="is-3-column">
    <nav class="navbar navbar-main">
    <div class="container">
        <div class="navbar-brand is-flex-center">
            <a class="navbar-item navbar-logo" href="/">
            
                <img src="/images/favicon.svg" alt="EM算法" height="28">
            
            </a>
        </div>
        <div class="navbar-menu">
            
            <div class="navbar-start">
                
                <a class="navbar-item" href="/">主页</a>
                
                <a class="navbar-item" href="/archives/">归档</a>
                
                <a class="navbar-item" href="/categories/">类别</a>
                
                <a class="navbar-item" href="/tags/">标签</a>
                
                <a class="navbar-item" href="/about/">关于</a>
                
            </div>
            
            <div class="navbar-end">
                
                    
                    
                    <a class="navbar-item" target="_blank" title="Xuan Hua&#39;s GitHub" href="https://www.github.com/huaxuan0720">
                        
                        <i class="fab fa-github"></i>
                        
                    </a>
                    
                
                
                <a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;">
                    <i class="fas fa-list-ul"></i>
                </a>
                
                
                <a class="navbar-item search" title="Search" href="javascript:;">
                    <i class="fas fa-search"></i>
                </a>
                
            </div>
        </div>
    </div>
</nav>
    
    <section class="section">
        <div class="container">
            <div class="columns">
                <div class="column is-8-tablet is-8-desktop is-9-widescreen has-order-2 column-main"><div class="card">
    
    <div class="card-image">
        <span class="image is-7by1">
            <img class="thumbnail" src="/gallery/MachineLearning.jpg" alt="EM算法">
        </span>
    </div>
    
    <div class="card-content article ">
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <i class="fas fa-angle-double-right"></i>EM算法
            
        </h1>
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2019-05-10T05:36:51.000Z"><i class="far fa-calendar-alt">&nbsp;</i>2019-05-10</time>
                
                <time class="level-item has-text-grey is-hidden-mobile" datetime="2019-06-03T07:34:31.751Z"><i class="far fa-calendar-check">&nbsp;</i>2019-06-03</time>
                
                
                <div class="level-item">
                <i class="far fa-folder-open has-text-grey"></i>&nbsp;
                <a class="has-link-grey -link" href="/categories/机器学习/">机器学习</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    <i class="far fa-clock"></i>&nbsp;
                    
                    
                    42 minutes read (About 6261 words)
                </span>
                
                
                <span class="level-item has-text-grey" id="busuanzi_container_page_pv">
                    <i class="far fa-eye"></i>
                    <span id="busuanzi_value_page_pv">0</span> visits
                </span>
                
            </div>
        </div>
        
        <div class="content">
            <h5 id="前言">前言</h5>
<p>  EM算法是一种可以求解含有隐变量的迭代算法，当我们在实际过程中收集数据的时候，并不一定会收集全部的有效信息。比如，当我们想统计全校学生的身高分布的时候，可以将全校学生的身高看作是一个正态分布，但是毕竟男生和女生之间身高的分布还是有些不同的，但是万一我们没有对性别信息进行统计，而只是统计了身高信息的话，求得的概率分布的参数肯定会有较大的误差，这个时候，我们就需要将每一个样本的性别分布也考虑进去，从而希望获得更准确的概率分布估计。</p>
<a id="more"></a>
<h5 id="一准备工作">一、准备工作</h5>
<h6 id="极大似然估计">1、极大似然估计</h6>
<p>  极大似然估计我们并不陌生，在逻辑回归的求解过程中，我们就是用了极大似然估计，现在还是简单说明一下。</p>
<p>  假设我们现在有一个概率分布，不妨记作<span class="math inline">\(P(x;\theta)\)</span>，其中，<span class="math inline">\(\theta\)</span>是未知参数，有可能是一个数值，也有可能是多个数值组成的参数向量，<span class="math inline">\(x\)</span>表示输入样本。现在我们想通过抽样的方式对参数<span class="math inline">\(\theta\)</span>进行估计。假设我们一共采集了<span class="math inline">\(N\)</span>组数据，为<span class="math inline">\(\{x_1, x_2, \cdots, x_N\}\)</span>。那么样本的联合概率函数可以表示为关于<span class="math inline">\(\theta\)</span>的函数，即： <span class="math display">\[
L(\theta) = L(x_1, x_2, \cdots, x_N;\theta) = \prod_i^N P(x_i;\theta)
\]</span>   <span class="math inline">\(L(\theta)\)</span>是参数 <span class="math inline">\(θ\)</span> 的函数，随着 <span class="math inline">\(θ\)</span> 在参数变化，<span class="math inline">\(L\)</span>函数也在变化。而极大似然估计目的就是在样本<span class="math inline">\(\{x_1,...,x_N\}\)</span>固定的情况下，寻找最优的 <span class="math inline">\(θ\)</span> 来极大化似然函数： <span class="math display">\[
\theta^{*} = \mathop{\arg\max}_{\theta}{L(\theta)}
\]</span>   上式在数学领域，可以看作是对 <span class="math inline">\(θ^{*}\)</span>求解，求<span class="math inline">\(L(θ)\)</span> 函数的极值点，导数为0处，即为 <span class="math inline">\(θ*\)</span> 的点。</p>
<p>  又因为<span class="math inline">\(L(θ)\)</span> 和 <span class="math inline">\(ln(θ)\)</span> 在同一个 <span class="math inline">\(θ\)</span> 处取得极值，我们可以对 <span class="math inline">\(L(θ)\)</span> 取对数，将连乘转化为连加(方便求导)，得到对数化似然函数： <span class="math display">\[
\theta^*= \mathop{\arg\max}_{\theta}{ln\;L(\theta)} = \mathop{\arg\max}_{\theta} \sum_i ln\; P(x_i;\theta)
\]</span></p>
<h6 id="jensen不等式">2、Jensen不等式</h6>
<p>  下图是一张描述Jensen不等式十分经典的图。</p>
<p><img src="/2019/05/10/Note2-EM-Algorithm/Jensen.png"></p>
<p>  如果一个函数<span class="math inline">\(f(x)\)</span>在其定义域内是一个连续函数，且其二阶导数恒小于等于0，我们称该函数在其定义域上是凹函数，反之，如果二阶导数恒大于等于0，我们称该函数在其定义域上是凸函数。</p>
<p>  如果<span class="math inline">\(f(x)\)</span>是一个凸函数，那么在其定义域上我们有: <span class="math display">\[
E(f(X)) \geq f(E(X))
\]</span>   反之，如果<span class="math inline">\(f(x)\)</span>是一个凹函数，在其定义域上我们有： <span class="math display">\[
E(f(X)) \leq f(E(X))
\]</span>   其中，<span class="math inline">\(E\)</span>表示对变量取期望。上面两个不等式当且仅当<span class="math inline">\(X\)</span>是一个常量时可以取等号。</p>
<h6 id="边缘分布">3、边缘分布</h6>
<p>  假设我们有两个随机变量，那么我们通过抽样，就会获得一个二维的联合概率分布<span class="math inline">\(P(X=x_i,Y=y_j)\)</span>。</p>
<p>  对每一个<span class="math inline">\(X=x_i\)</span>，对其所有的<span class="math inline">\(Y\)</span>进行求和操作，我们有： <span class="math display">\[
\sum_{y_j}P(X=x_i, Y=y_j) = P(X=x_i)
\]</span>   将上面的式子称之为<span class="math inline">\(X=x_i\)</span>的边际分布（边缘分布）。</p>
<p>​ 有了以上的一些基础准备，我们就可以来推导EM算法了。</p>
<h5 id="二em算法">二、EM算法</h5>
<p>  假设我们的数据集为： <span class="math display">\[
D = \{x^{(1)}, x^{(2)}, \cdots, x^{(N)}\}
\]</span></p>
<p>  其中 <span class="math inline">\(x^{(i)}\)</span> 是每一个具体的输出实例，表示每一次独立实验的结果，<span class="math inline">\(N\)</span>表示独立实验的次数。</p>
<p>  我们设样本的概率分布函数为<span class="math inline">\(P(x^{(i)};\theta)\)</span>，其中<span class="math inline">\(\theta\)</span>是模型中的待估参数，可以是一个变量，也可以是多个变量所组成的参数向量。</p>
<p>  根据极大似然估计，我们有： <span class="math display">\[
L(\theta) = \prod_{i}P(x^{(i)}; \theta) \quad 1 \leq i \leq N \tag{1}
\]</span>   两边同时取对数： <span class="math display">\[
ln\;L(\theta) = \sum_{i} ln \; P(x^{(i)}; \theta) \quad 1 \leq i \leq N \tag{2}
\]</span>   此时，我们可以将 <span class="math inline">\(P(x^{(i)}; \theta)\)</span>看作是关于隐变量的一个边缘分布，即（我们假设隐变量为<span class="math inline">\(Z\)</span>）： <span class="math display">\[
ln \; L(\theta) = \sum_i ln \; \sum_{z^{(i)}} P(x^{(i)}, z^{(i)}; \theta) \quad 1 \leq i \leq N \tag{3}
\]</span>   这里我们利用了边缘分布的相关等式，即： <span class="math display">\[
P(x^{(i)}; \theta) = \sum_{z^{(i)}} P(x^{(i)}, z^{(i)}; \theta)
\]</span>   在上面的式子中，<span class="math inline">\(z\)</span>是一个隐藏变量，必然也会满足一个特定的概率分布，我们不妨把这个分布记作<span class="math inline">\(Q_{i}(z^{(i)})\)</span>，显然，我们有<span class="math inline">\(\sum_{z^{(i)}} Q_i(z^{(i)}) = 1\)</span>。这里的下标和上标<span class="math inline">\(i\)</span>表示的是第<span class="math inline">\(i\)</span>个样本。故我们将上式改写成： <span class="math display">\[
\begin{aligned}
ln \; L(\theta) &amp;=&amp; \sum_i ln \sum_{z^{(i)}} P(x^{(i)}, z^{(i)}; \theta) \\
&amp;=&amp; \sum_i ln \sum_{z^{(i)}} Q_i(z^{(i)}) \cdot \frac{P(x^{(i)}, z^{(i)}; \theta)}{Q_i(z^{(i)})} 
\end{aligned} \tag{4}
\]</span>   现在，我们把如下的部分单独拿出来： <span class="math display">\[
Q_i(z^{(i)}) = p(z^{(i)}) \\
\frac{P(x^{(i)}, z^{(i)}; \theta)}{Q_i(z^{(i)})} = f(z^{(i)})
\]</span>   很显然，我们有<span class="math inline">\(\sum_{z^{(i)}} Q_i(z^{(i)}) = \sum_i p(z^{(i)}) = 1\)</span>，所以，我们可以将上式写成： <span class="math display">\[
ln \; L(\theta) = \sum_i ln \sum_{z^{(i)}} p(z^{(i)}) f(z^{(i)}) \tag{5}
\]</span>   可以看出，我们的<span class="math inline">\(\sum_{z^{(i)}} p(z^{(i)}) f(z^{(i)})\)</span>实际上实在对<span class="math inline">\(f(z^{(i)})\)</span>计算期望，其中<span class="math inline">\(p(z^{(i)})\)</span>是函数<span class="math inline">\(f(z^{(i)})\)</span>的概率分布函数，于是，我们可以把上面的式子记作： <span class="math display">\[
E[f(z^{(i)})] = \sum_{z^{(i)}} Q_i(z^{(i)}) \cdot \frac{P(x^{(i)}, z^{(i)}; \theta)}{Q_i(z^{(i)})} \tag{6}
\]</span>   于是，我们的似然函数就变成了： <span class="math display">\[
ln \; L(\theta) = \sum_i ln \;(E[f(z^{(i)})]) = \sum_i ln \; (E[\frac{P(x^{(i)}, z^{(i)}; \theta)}{Q_i(z^{(i)})}]) \tag{7}
\]</span>   这个时候就是Jensen不等式出场的时候了。</p>
<p>  我们观察到函数<span class="math inline">\(g(x)=ln(x)\)</span>，它的一阶导数是<span class="math inline">\(g&#39;(x) = \frac{1}{x}\)</span>，二阶导数是<span class="math inline">\(g&#39;&#39;(x) = - \frac{1}{x^2}\)</span>恒小于0，因此<span class="math inline">\(g(x) = ln(x)\)</span>是一个凹函数，此时，我们利用Jensen不等式处理<span class="math inline">\(ln \;L(\theta)\)</span>，有： <span class="math display">\[
\begin{aligned}
H(Y|X)&amp; =\sum_{x\in X} p(x)H(Y|X) \\
&amp; =-\sum_{x\in X} p(x)\sum_{y\in Y}p(y|x)\log p(y|x)\\
&amp; =-\sum_{x\in X} \sum_{y\in Y}p(y,x)\log p(y|x)
\end{aligned}
\]</span>   故：我们根据Jensen不等式，有了以下的一个重要的不等式关系： <span class="math display">\[
ln \; L(\theta) \geq \sum_i \sum_{z^{(i)}} Q_i(z^{(i)}) \cdot ln(\frac{P(x^{(i)}, z^{(i)}; \theta)}{Q_i(z^{(i)})})) \tag{9}
\]</span>   需要注意的是，我们使用Jensen不等式的时候，是对<span class="math inline">\(z^{(i)}\)</span>的分布使用的，而<span class="math inline">\(\sum_i \sum_{z^{(i)}} Q_i(z^{(i)}) \cdot ln(\frac{P(x^{(i)}, z^{(i)}; \theta)}{Q_i(z^{(i)})}))\)</span>是函数<span class="math inline">\(ln \; L(\theta)\)</span>的一个下界，所以实际上，<span class="math inline">\(ln \; L(\theta)\)</span>包含了两个参数变量，一个是<span class="math inline">\(\theta\)</span>， 一个是隐藏变量<span class="math inline">\(z^{(i)}\)</span>，所以我们需要弄清楚调整<span class="math inline">\(\theta\)</span>和<span class="math inline">\(z^{(i)}\)</span>的区别。</p>
<p>  由于Jensen不等式处理的是<span class="math inline">\(z^{(i)}\)</span>，因此当我们调整<span class="math inline">\(z^{(i)}\)</span>的时候，我们实际上实在调整似然函数<span class="math inline">\(ln \; L(\theta)\)</span>的下界，使得似然函数<span class="math inline">\(ln \; L(\theta)\)</span>的下界一点一点上升，最终于此时的似然函数<span class="math inline">\(ln \; L(\theta)\)</span>的值相等。</p>
<p>  然后，固定<span class="math inline">\(z^{(i)}\)</span>的数值，调整<span class="math inline">\(\theta\)</span>的时候，就可以将<span class="math inline">\(z^{(i)}\)</span>看作是一个已知变量，这个时候就可以利用极大似然估计的方法对<span class="math inline">\(\theta\)</span>参数的值进行计算，此时会得到一个新的<span class="math inline">\(\theta\)</span>的值，不妨记作<span class="math inline">\(\theta&#39;\)</span>。我们这个时候再根据这个新的<span class="math inline">\(\theta&#39;\)</span>的值，重新调整<span class="math inline">\(z^{(i)}\)</span>，使得函数的下界一点一点上升，达到和<span class="math inline">\(ln \; L(\theta)\)</span>相同之后，再固定<span class="math inline">\(z^{(i)}\)</span>，更新<span class="math inline">\(\theta\)</span>的值。一直重复以上过程，直到似然函数收敛到某一个极大值<span class="math inline">\(\theta^*\)</span>处。</p>
<p>  下图是一个很经典的关于EM算法的迭代过程示意图。（图片来自网络）</p>
<p><img src="/2019/05/10/Note2-EM-Algorithm/EM.jpg"></p>
<p>  在上面的求解过程中，只有当此时的函数下界等于当前<span class="math inline">\(\theta\)</span>的对数似然函数时，才能保证当我们优化了这个下界的时候，才真正优化了目标似然函数。 <span class="math display">\[
ln \; L(\theta) \geq \sum_i \sum_{z^{(i)}} Q_i(z^{(i)}) \cdot ln(\frac{P(x^{(i)}, z^{(i)}; \theta)}{Q_i(z^{(i)})})) \tag{10}
\]</span>   在优化迭代的过程中，我们通过固定<span class="math inline">\(\theta\)</span>并调整<span class="math inline">\(z^{(i)}\)</span>的可能分布，使得等式成立，即达到<span class="math inline">\(ln \; L(\theta)\)</span>的下界。根据Jensen不等式的条件，当<span class="math inline">\(f(x)\)</span>是一个凹函数的时候，有<span class="math inline">\(f(E[X]) \geq E[f(X)]\)</span>，欲使等号成立，<span class="math inline">\(X\)</span>需要是一个常量。那么，在上面的式子中，我们有<span class="math inline">\(X = \frac{P(x^{(i)}, z^{(i)}; \theta)}{Q_i(z^{(i)})}\)</span>，故此时我们需要将<span class="math inline">\(\frac{P(x^{(i)}, z^{(i)}; \theta)}{Q_i(z^{(i)})})\)</span>看作一个常数，不妨我们设这个常数为<span class="math inline">\(C\)</span>，于是我们有： <span class="math display">\[
\frac{P(x^{(i)}, z^{(i)}; \theta)}{Q_i(z^{(i)})}) = C \tag{11}
\]</span> <span class="math display">\[
P(x^{(i)}, z^{(i)}; \theta) = C Q_i(z^{(i)})
\]</span> <span class="math display">\[
\sum_{z^{(i)}} P(x^{(i)}, z^{(i)}; \theta) = C \sum_{z^{(i)}} Q_i(z^{(i)}) \tag{12}
\]</span>   考虑到<span class="math inline">\(Q_i(z^{(i)})\)</span>实际上是隐变量<span class="math inline">\(z^{(i)}\)</span>的一个概率分布，满足： <span class="math display">\[
\sum_{z^{(i)}} Q_i(z^{(i)}) = 1 ,\quad Q_i(z^{(i)}) \geq 0
\]</span>   于是，我们将<span class="math inline">\(\sum_{z^{(i)}} Q_i(z^{(i)}) = 1\)</span>代入到上面的式子(12)中，有： <span class="math display">\[
\sum_{z^{(i)}} P(x^{(i)}, z^{(i)}; \theta) = C \tag{11}
\]</span>   再将<span class="math inline">\(C\)</span>带入到公式(11)中，我们有： <span class="math display">\[
\frac{P(x^{(i)}, z^{(i)}; \theta)}{Q_i(z^{(i)})} = C = \sum_{z^{(i)}} P(x^{(i)}, z^{(i)}; \theta)
\]</span></p>
<p><span class="math display">\[
\begin{aligned}
Q_i(z^{(i)}) &amp;= \frac{P(x^{(i)}, z^{(i)};\theta)}{\sum_{z^{(i)}} P(x^{(i)}, z^{(i)}; \theta)} \\
&amp;= \frac{P(x^{(i)}, z^{(i)};\theta)}{P(x^{(i)};\theta)} \\
&amp;= P(z^{(i)}|x^{(i)};\theta)
\end{aligned} \tag{12}
\]</span></p>
<p>   即我们可以得到<span class="math inline">\(Q_i(z^{(i)})\)</span>的值，也即我们得到<span class="math inline">\(P(z^{(i)}|x^{(i)};\theta)\)</span>的值，表示在当前的模型参数<span class="math inline">\(\theta\)</span>为定值时，在给定的<span class="math inline">\(x^{(i)}\)</span>的条件下，得到<span class="math inline">\(z^{(i)}\)</span>的概率大小。</p>
<p>   至此，我们的EM算法的大部分情况进行了说明。首先，我们会对模型的参数<span class="math inline">\(\theta\)</span> 进行随机初始化，不妨记作<span class="math inline">\(\theta^0\)</span>。然后会在每一次的迭代循环中计算<span class="math inline">\(z^{(i)}\)</span>的条件概率期望，这就是EM算法中的”E步“。最后再根据计算得到的概率分布，根据极大似然的方法计算在当前隐藏变量分布下的使得似然函数取得极大的<span class="math inline">\(\theta\)</span>的值，并进行更新，这就是EM算法中的”M步“。</p>
<p>  观察到在”M步“中，我们有： <span class="math display">\[
ln \; L(\theta) = \sum_i \sum_{z^{(i)}} Q_i(z^{(i)}) \cdot ln(\frac{P(x^{(i)}, z^{(i)}; \theta)}{Q_i(z^{(i)})}))
\]</span></p>
<p><span class="math display">\[
\theta^{(j + 1)} = \mathop{\arg\max}_{\theta}\sum_i \sum_{z^{(i)}} Q_i(z^{(i)}) ln (P(x^{(i)}, z^{(i)};\theta)) - \sum_i \sum_{z^{(i)}} Q_i(z^{(i)})ln(Q_i(z^{(i)}))
\]</span></p>
<p>  观察到在上面的式子中，<span class="math inline">\(\sum_i \sum_{z^{(i)}} Q_i(z^{(i)})ln(Q_i(z^{(i)}))\)</span>对于整个优化的过程来说相当于是一个常数项，因此可以省略，于是，上式可以简写成： <span class="math display">\[
\begin{aligned}
\theta^{(j + 1)} &amp;= \mathop{\arg\max}_{\theta}\sum_i \sum_{z^{(i)}} Q_i(z^{(i)}) ln (P(x^{(i)}, z^{(i)};\theta)) \\
&amp;=  \mathop{\arg\max}_{\theta}\sum_i \sum_{z^{(i)}} P(z^{(i)}|x^{(i)};\theta^{(j)}) ln (P(x^{(i)}, z^{(i)};\theta))
\end{aligned} \tag{13}
\]</span>   公式(13)内部的<span class="math inline">\(\sum_i \sum_{z^{(i)}} P(z^{(i)}|x^{(i)};\theta^{(j)}) ln (P(x^{(i)}, z^{(i)};\theta))\)</span>就是EM算法的核心，我们一般将其称之为<strong>Q函数</strong>，通常记为：<span class="math inline">\(Q(\theta, \theta^{(j)})\)</span>。</p>
<p>  所以，我们的<strong>EM算法可以总结如下</strong>：</p>
<ol type="1">
<li><p>数据集为<span class="math inline">\(D = \{x^{(1)}, x^{(2)}, \cdots, x^{(N)}\}\)</span> ，随机初始化模型参数<span class="math inline">\(\theta\)</span>，记作<span class="math inline">\(\theta^{(0)}\)</span>。</p></li>
<li><p>对每一次迭代循环，<span class="math inline">\(j = 0, 1, 2, 3, \cdots, M\)</span>，我们有：</p>
<p>2.1 E步（E-Step）：在当前的模型参数<span class="math inline">\(\theta^{(j)}\)</span>的条件下，计算联合分布的条件概率期望：</p></li>
</ol>
<p><span class="math display">\[
Q_i(z^{(i)}) = P(z^{(i)}|x^{(i)};\theta^{(j)})
\]</span></p>
<p>2.2 M步（M-Step）：在计算出条件概率分布的期望的基础上，极大化似然函数，得到新的模型参数<span class="math inline">\(\theta^{(j+1)}\)</span>的值:</p>
<p><span class="math display">\[
\theta^{(j+1)} = \mathop{\arg\max}_{\theta}\sum_i \sum_{z^{(i)}} P(z^{(i)}|x^{(i)};\theta^{(j)}) ln (P(x^{(i)}, z^{(i)};\theta))
\]</span></p>
<ol start="3" type="1">
<li><p>如果<span class="math inline">\(\theta^{(j+1)}\)</span>已经收敛，则跳出循环结束：</p></li>
<li><p>输出最后模型参数<span class="math inline">\(\theta\)</span>的值。</p></li>
</ol>
<h5 id="三em算法解决三硬币模型">三、EM算法解决三硬币模型</h5>
<p>  三硬币模型是EM算法的一个简单使用，问题请参考《统计学习方法》一书。</p>
<p>  假设有三枚质量分布不均匀的硬币A、B、C，这些硬币正面出现的概率分别是<span class="math inline">\(\pi\)</span>、<span class="math inline">\(p\)</span>、<span class="math inline">\(q\)</span>。进行如下掷硬币试验： 先掷A，如果A是正面则再掷B，如果A是反面则再掷C。对于B或C的结果，如果是正面则记为1，如果是反面则记为0。进行N次独立重复实验，得到结果。现在只能观测到结果，不能观测到掷硬币的过程，估计模型参数<span class="math inline">\(\theta=(\pi,p,q)\)</span>。</p>
<p>  由于实验一共进行了N次，每一次都是独立重复实验，那么我们可以将实验结果记录如下，其中每一次的实验结果是已知的： <span class="math display">\[
X = \{x^{(1)}, x^{(2)}, \cdots, x^{(N)}\} \quad x^{(i)} \in \{0, 1\}
\]</span>   每次独立实验都会产生一个隐藏变量<span class="math inline">\(z^{(i)}\)</span>，这个隐藏变量是无法被观测到的，我们可以将其记录如下，这个隐藏变量的记录结果是未知的： <span class="math display">\[
Z = \{z^{(1)}, z^{(2)}, \cdots, z^{(N)}\} \quad z^{(i)} \in \{0, 1\}
\]</span>   对于第<span class="math inline">\(i\)</span>次的独立重复实验，我们有： <span class="math display">\[
P(x^{(i)} = 0;\theta) = \pi(1-p)^{1-x^{(i)}} + (1-\pi)(1-q)^{1-x^{(i)}}
\]</span></p>
<p><span class="math display">\[
P(x^{(i)}=1;\theta) = \pi p^{x^{(i)}} + (1-\pi)q^{1-x^{(i)}}
\]</span></p>
<p>  故，综合起来看，我们有： <span class="math display">\[
P(x^{(i)};\theta) = \pi p^{x^{(i)}} (1-p)^{1-x^{(i)}} + (1-\pi)q^{x^{(i)}}(1-q)^{1-x^{(i)}}
\]</span></p>
<h6 id="构造极大似然函数">构造极大似然函数</h6>
<p>  我们可以构造我们的极大似然函数如下： <span class="math display">\[
\begin{aligned}
L(\theta) &amp;= \prod_i P(x^{(i)};\theta) \\
&amp;= \prod_i [\pi p^{x^{(i)}} (1-p)^{1-x^{(i)}} + (1-\pi)q^{x^{(i)}}(1-q)^{1-x^{(i)}}]
\end{aligned}
\]</span>   两边同时取对数，有： <span class="math display">\[
ln \; L(\theta) = \sum_i ln\;[\pi p^{x^{(i)}} (1-p)^{1-x^{(i)}} + (1-\pi)q^{x^{(i)}}(1-q)^{1-x^{(i)}}]
\]</span></p>
<h6 id="构造我们的q函数">构造我们的Q函数</h6>
<p>  在没有说明的情况下，我们使用下标表示第几次迭代过程，用上标表示第几个样本，<span class="math inline">\(\theta^{(j)}\)</span>的上标表示第<span class="math inline">\(j\)</span>次迭代。</p>
<p>  对于三硬币问题，我们的Q函数可以构造如下： <span class="math display">\[
\begin{aligned}
Q(\theta, \theta^{(j)}) &amp;= \sum_i \sum_{z^{(i)}} P(z^{(i)}|x^{(i)};\theta^{(j)}) ln (P(x^{(i)}, z^{(i)};\theta)) \\
&amp;= \sum_i \{P(z^{(i)} =1|x^{(i)};\theta^{(j)})\cdot ln\;P(x^{(i)}, z^{(i)}=1;\theta) + P(z^{(i)} =0|x^{(i)};\theta^{(j)})\cdot ln\;P(x^{(i)}, z^{(i)}=0;\theta)\} \\
\end{aligned}
\]</span>   故，我们需要求解<span class="math inline">\(P(z^{(i)} =1|x^{(i)};\theta^{(j)})\)</span>，<span class="math inline">\(P(x^{(i)}, z^{(i)}=1;\theta)\)</span>，<span class="math inline">\(P(z^{(i)} =0|x^{(i)};\theta^{(j)})\)</span>，<span class="math inline">\(P(x^{(i)}, z^{(i)}=0;\theta)\)</span>这四个概率值。</p>
<h6 id="求解极大值">求解极大值</h6>
<p><span class="math display">\[
\begin{aligned}
P(z^{(i)}=1|x^{(i)};\theta^{(j)}) &amp;= \frac{P(x^{(i)}, z^{(i)}=1;\theta^{(j)})}{P(x^{(i)});\theta^{(j)})} \\
&amp;= \frac{\pi_j \cdot p_j^{x^{(i)}} \cdot (1 - p_j^{(1-x^{(i)})})}{\pi_j \cdot p_j^{x^{(i)}} \cdot (1 - p_j^{(1-x^{(i)})}) + (1-\pi_j) \cdot q_j^{x^{(i)}} \cdot (1-q_j)^{1-x^{(i)}}} \\
&amp;= \mu_j^{(i)}
\end{aligned}
\]</span></p>
<p>  上式对于迭代过程来说是一个定值，我们使用符号<span class="math inline">\(\mu_j^{(i)}\)</span>来表示，上标<span class="math inline">\((i)\)</span>表示的是第<span class="math inline">\(i\)</span>个样本，下标<span class="math inline">\(j\)</span>表示的是第<span class="math inline">\(j\)</span>次迭代过程。</p>
<p>  那么很明显，我们有： <span class="math display">\[
\begin{aligned}
P(z^{(i)}=0|x^{(i)};\theta^{(j)}) &amp;= \frac{P(x^{(i)}, z^{(i)}=0;\theta^{(j)})}{P(x^{(i)});\theta^{(j)})} \\
&amp;= \frac{(1-\pi_j) \cdot q_j^{x^{(i)}} \cdot (1-q_j)^{1-x^{(j)}}}{\pi_j \cdot p_j^{x^{(i)}} \cdot (1 - p_j^{(1-x^{(i)})}) + (1-\pi_j) \cdot q_j^{x^{(i)}} \cdot (1-q_j)^{1-x^{(i)}}} \\
&amp;= 1 - \mu_j^{(i)}
\end{aligned}
\]</span>   接着，我们计算<span class="math inline">\(P(x^{(i)}, z^{(i)}=1;\theta)\)</span>，<span class="math inline">\(P(x^{(i)}, z^{(i)}=0;\theta)\)</span>： <span class="math display">\[
P(x^{(i)}, z^{(i)}=1;\theta) = \pi \cdot p^{x^{(i)}} \cdot (1-p)^{1-x^{(i)}}
\]</span></p>
<p><span class="math display">\[
P(x^{(i)}, z^{(i)}=0;\theta)=(1-\pi) \cdot q^{(i)}\cdot (1-q)^{1-x^{(i)}}
\]</span></p>
<p>  我们将上面的计算结果都带入到Q函数中，有： <span class="math display">\[
\begin{aligned}
Q(\theta, \theta^{(j)}) &amp;= \sum_i \sum_{z^{(i)}} P(z^{(i)}|x^{(i)};\theta^{(j)}) ln (P(x^{(i)}, z^{(i)};\theta)) \\
&amp;= \sum_i \{P(z^{(i)} =1|x^{(i)};\theta^{(j)})\cdot ln\;P(x^{(i)}, z^{(i)}=1;\theta) + P(z^{(i)} =0|x^{(i)};\theta^{(j)})\cdot ln\;P(x^{(i)}, z^{(i)}=0;\theta)\} \\
&amp;= \sum_i \{\mu_j^{(i)} \cdot  ln\;[\pi \cdot p^{x^{(i)}} \cdot (1-p)^{1-x^{(i)}}] + (1-\mu_j^{(i)})\cdot ln\; [(1-\pi) \cdot q^{(i)}\cdot (1-q)^{1-x^{(i)}}]\}
\end{aligned}
\]</span></p>
<p>  下一步就是对我们需要求解的变量进行求偏导数的操作，如下： <span class="math display">\[
\begin{aligned}
\frac{\partial Q}{\partial \pi} &amp;= \sum_i \{\mu_j^{(i)} \cdot \frac{p^{x^{(i)}} \cdot (1-p)^{1-x^{(i)}}}{\pi \cdot p^{x^{(i)}} \cdot (1-p)^{1-x^{(i)}}} + (1-\mu_j^{(i)})\cdot \frac{-1 \cdot q^{(i)}\cdot (1-q)^{1-x^{(i)}}}{(1-\pi) \cdot q^{(i)}\cdot (1-q)^{1-x^{(i)}}}\} \\
&amp;= \sum_i \{\mu_j^{(i)} \cdot \frac{1}{\pi} + (\mu_j^{(i)}-1)\cdot \frac{1}{1-\pi}\} \\
&amp;= \sum_i \{\mu_j^{(i)}(\frac{1}{\pi} + \frac{1}{1-\pi}) - \frac{1}{1-\pi} \} \\
&amp;= \sum_i \{\mu_j^{(i)} \cdot \frac{1}{\pi(1-\pi)}\} - \frac{N\pi}{\pi(1-\pi)} \\
&amp;= \frac{1}{\pi(1-\pi)}\{\sum_i \mu_j^{(i)} - N\pi\}
\end{aligned}
\]</span>   令上式为0，我们有： <span class="math display">\[
\sum_i \mu_j^{(i)} - N\pi = 0
\]</span>   即： <span class="math display">\[
\pi = \frac{1}{N} \sum_i \mu_j^{(i)}
\]</span>   同样的道理，我们可以计算出Q函数相对于<span class="math inline">\(p\)</span>的偏导数，如下： <span class="math display">\[
\begin{aligned}
\frac{\partial Q}{\partial p} &amp;= \sum_i \mu_j^{(i)} \frac{x^{(i)} \cdot p^{x^{(i)}-1} \cdot (1-p)^{1-x^{(i)}} + p^{x^{(i)}}\cdot (1-x^{(i)})\cdot (1-p)^{-x^{(i)}}\cdot (-1)}{p^{x^{(i)}}\cdot (1-p)^{1-x^{(i)}}} + 0 \\
&amp;= \sum_i \mu_j^{(i)} \frac{\frac{x^{(i)}}{p}\cdot p^{x^{(i)}}\cdot (1-p)^{1-x^{(i)}} + p^{x^{(i)}}\cdot (1-p)^{1-x^{(i)}} \cdot \frac{1}{1-p}\cdot (1-x^{(i)})\cdot (-1)}{p^{x^{(i)}}\cdot (1-p)^{1-x^{(i)}}} \\
&amp;= \sum_i \mu_j^{(i)} \{\frac{x^{(i)}}{p} + \frac{1-x^{(i)}}{p-1}\} \\
&amp;= \sum_i \mu_j^{(i)} \cdot \frac{(p-1)\cdot x^{(i)} + p(1-x^{(i)})}{p(p-1)} \\
&amp;= \frac{1}{p(p-1)} \sum_i \mu_j^{(i)} \{p-x^{(i)}\} \\
&amp;= \frac{1}{p(p-1)}\{p \cdot \sum_i \mu_j^{(i)} - \sum_i \mu_j^{(i)} \cdot x^{(i)}\} 
\end{aligned}
\]</span>   令上式等于0，我们可以得到： <span class="math display">\[
p \cdot \sum_i \mu_j^{(i)} - \sum_i \mu_j^{(i)} \cdot x^{(i)} = 0
\]</span>   即： <span class="math display">\[
p = \frac{\sum_i \mu_j^{(i)\cdot x^{(i)}}}{\sum_i \mu_j^{(i)}}
\]</span>   同理，我们对<span class="math inline">\(q\)</span>求偏导数，有： <span class="math display">\[
\begin{aligned}
\frac{\partial Q}{\partial q} &amp;= \sum_i (1-\mu_j^{(i)})(\frac{x^{(i)}}{q}+\frac{1-x^{(i)}}{p-1}) \\
&amp;= \sum_i (1-\mu_j^{(i)})\frac{q-x^{(i)}}{q(q-1)} \\
&amp;= \frac{1}{q(q-1)}\{q\cdot \sum_i (1-\mu_j^{(i)}) - \sum_i (1-\mu_j^{(i)})x^{(i)}    \}
\end{aligned}
\]</span>   令上式等于0，我们有： <span class="math display">\[
q\cdot \sum_i (1-\mu_j^{(i)}) - \sum_i (1-\mu_j^{(i)})x^{(i)} =0
\]</span>   即： <span class="math display">\[
q = \frac{\sum_i (1-\mu_j^{(i)})x^{(i)}}{\sum_i (1-\mu_j^{(i)})}
\]</span>   所以，以上就是我们解决三硬币模型的迭代公式的求解过程，公式汇总如下，这里加入了下标，表示新的一轮迭代变量： <span class="math display">\[
\mu_j^{(i)} = \frac{\pi_j \cdot p_j^{x^{(i)}} \cdot (1 - p_j^{(1-x^{(i)})})}{\pi_j \cdot p_j^{x^{(i)}} \cdot (1 - p_j^{(1-x^{(i)})}) + (1-\pi_j) \cdot q_j^{x^{(i)}} \cdot (1-q_j)^{1-x^{(i)}}}
\]</span></p>
<p><span class="math display">\[
\pi_{j+1} = \frac{1}{N} \sum_i \mu_j^{(i)}
\]</span></p>
<p><span class="math display">\[
p_{j+1}  = \frac{\sum_i \mu_j^{(i)\cdot x^{(i)}}}{\sum_i \mu_j^{(i)}}
\]</span></p>
<p><span class="math display">\[
q_{j+1}  = \frac{\sum_i (1-\mu_j^{(i)})x^{(i)}}{\sum_i (1-\mu_j^{(i)})}
\]</span></p>
<h5 id="四em算法的收敛性">四、EM算法的收敛性</h5>
<p>  在之前的过程中，我们都是默认EM算法可以收敛到某一极大值附近，但是并没有给出十分严格的证明，所以，我们需要对EM的收敛性进行一定的验证。</p>
<p>  由于我们是利用极大似然估计来估计参数的值，那么，我们只需要保证在每一次的迭代过程中，似然函数的数值都在上升即可，即下面的不等式成立： <span class="math display">\[
ln \; L(\theta^{(j+1)}) \geq ln\;L(\theta^{(j)})
\]</span>   由于： <span class="math display">\[
P(x^{(i)};\theta) = \frac{P(x^{(i)}, z^{(i)};\theta)}{P(z^{(i)}|x^{(i)};\theta)}
\]</span>   因此，两边取对数，我们有： <span class="math display">\[
ln \; P(x^{(i)};\theta) = ln\; P(x^{(i)}, z^{(i)};\theta) - ln\;P(z^{(i)}|x^{(i)};\theta)
\]</span>   对每一个样本进行累加，我们有： <span class="math display">\[
\sum_i ln \; P(x^{(i)};\theta) = \sum_i (ln\; P(x^{(i)}, z^{(i)};\theta) - ln\;P(z^{(i)}|x^{(i)};\theta))
\]</span>   根据我们构造的Q函数，我们有： <span class="math display">\[
Q(\theta, \theta^{(j)}) = \sum_i \sum_{z^{(i)}} P(z^{(i)}|x^{(i)};\theta^{(j)}) ln (P(x^{(i)}, z^{(i)};\theta))
\]</span>   另，我们可以构造如下的一个函数，记作<span class="math inline">\(H(\theta, \theta^{(j)})\)</span>，如下： <span class="math display">\[
H(\theta, \theta^{(j)}) = \sum_i \sum_{z^{(i)}} P(z^{(i)}|x^{(i)};\theta^{(j)}) ln (P(z^{(i)}| x^{(i)};\theta))
\]</span>   我们将上面的两个函数相减，有： <span class="math display">\[
\begin{aligned}
Q(\theta, \theta^{(j)}) - H(\theta, \theta^{(j)}) &amp;=  \sum_i \sum_{z^{(i)}} P(z^{(i)}|x^{(i)};\theta^{(j)}) ln (P(x^{(i)}, z^{(i)};\theta)) \\&amp;\quad- \sum_i \sum_{z^{(i)}} P(z^{(i)}|x^{(i)};\theta^{(j)}) ln (P(z^{(i)}| x^{(i)};\theta)) \\
&amp;=  \sum_i \sum_{z^{(i)}} P(z^{(i)}|x^{(i)};\theta^{(j)}) (ln\;P(x^{(i)}, z^{(i)};\theta) - ln\;P(z^{(i)}| x^{(i)};\theta)) \\
&amp;= \sum_i \sum_{z^{(i)}} P(z^{(i)}|x^{(i)};\theta^{(j)})ln\;\frac{P(x^{(i)}, z^{(i)};\theta)}{P(z^{(i)}| x^{(i)};\theta)} \\
&amp;= \sum_i \sum_{z^{(i)}} P(z^{(i)}|x^{(i)};\theta^{(j)})ln\;P(x^{(i)};\theta) \\
&amp;= \sum_i ln\;P(x^{(i)};\theta) (\sum_{z^{(i)}}P(z^{(i)}|x^{(i)};\theta^{(j)}) ) \\
&amp;= \sum_i ln\;P(x^{(i)};\theta) \\
&amp;= ln \;L(\theta)
\end{aligned}
\]</span>   在上面的式子中，第三行是利用了条件概率的公式，第五行则是利用了<span class="math inline">\(\sum_{z^{(i)}}P(z^{(i)}|x^{(i)};\theta^{(j)}) = 1\)</span>的条件。</p>
<p>  所以，我们构造出的两个式子，相减之后正好是我们的极大似然函数的对数。</p>
<p>  于是，我们将<span class="math inline">\(ln\; L(\theta^{(j+1)})\)</span>和<span class="math inline">\(ln\;L(\theta^{(j)})\)</span>相减，我们有： <span class="math display">\[
\begin{aligned}
ln \; L(\theta^{(j+1)}) - ln\;L(\theta^{(j)}) &amp;= (Q(\theta^{(j+1)}, \theta^{(j)}) - H(\theta^{(j+1)}, \theta^{(j)})) - (Q(\theta^{(j)}, \theta^{(j)}) - H(\theta^{(j)}, \theta^{(j)})) \\
&amp;= (Q(\theta^{(j+1)}, \theta^{(j)})-Q(\theta^{(j)}, \theta^{(j)})) - (H(\theta^{(j+1)}, \theta^{(j)}) - H(\theta^{(j)}, \theta^{(j)}))
\end{aligned}
\]</span>   对于第一个括号内部的<span class="math inline">\(Q(\theta^{(j+1)}, \theta^{(j)})-Q(\theta^{(j)}, \theta^{(j)})\)</span>，由于我们是通过极大化Q函数来更新参数的数值，所以<span class="math inline">\(Q(\theta^{(j+1)}, \theta^{(j)}) \geq Q(\theta^{(j)}, \theta^{(j)})\)</span>，故这一部分一定会大于等于0，即： <span class="math display">\[
Q(\theta^{(j+1)}, \theta^{(j)})-Q(\theta^{(j)}, \theta^{(j)}) \geq 0
\]</span>   对于第二个括号内部的数值，我们有： <span class="math display">\[
\begin{aligned}
H(\theta^{(j+1)}, \theta^{(j)}) - H(\theta^{(j)}, \theta^{(j)}) &amp;=
\sum_i \sum_{z^{(i)}} P(z^{(i)}|x^{(i)};\theta^{(j)}) ln (P(z^{(i)}| x^{(i)};\theta^{(j+1)})) \\ &amp;\quad- \sum_i \sum_{z^{(i)}} P(z^{(i)}|x^{(i)};\theta^{(j)}) ln (P(z^{(i)}| x^{(i)};\theta^{(j)})) \\
&amp;= \sum_i \sum_{z^{(i)}} P(z^{(i)}|x^{(i)};\theta^{(j)}) ln\; \frac{P(z^{(i)}| x^{(i)};\theta^{(j+1)})}{P(z^{(i)}| x^{(i)};\theta^{(j)})} \\
&amp;\leq \sum_i ln(\sum_{z^{(i)}} \frac{P(z^{(i)}| x^{(i)};\theta^{(j+1)})}{P(z^{(i)}| x^{(i)};\theta^{(j)})} P(z^{(i)}|x^{(i)};\theta^{(j)})) \\
&amp;= \sum_i ln (\sum_{z^{(i)}} P(z^{(i)}| x^{(i)};\theta^{(j+1)})) \\
&amp;= \sum_i ln(1) \\
&amp;= 0
\end{aligned}
\]</span></p>
<p>  在上面的第三步中，我们使用了Jensen不等式，在第五步中，我们使用了<span class="math inline">\(\sum_{z^{(i)}} P(z^{(i)}| x^{(i)};\theta^{(j+1)}) = 1\)</span>这一条件。</p>
<p>  于是，我们可以有： <span class="math display">\[
Q(\theta^{(j+1)}, \theta^{(j)})-Q(\theta^{(j)}, \theta^{(j)}) \geq 0
\]</span></p>
<p><span class="math display">\[
H(\theta^{(j+1)}, \theta^{(j)}) - H(\theta^{(j)}, \theta^{(j)}) \leq 0
\]</span></p>
<p>  故： <span class="math display">\[
(Q(\theta^{(j+1)}, \theta^{(j)})-Q(\theta^{(j)}, \theta^{(j)})) - (H(\theta^{(j+1)}, \theta^{(j)}) - H(\theta^{(j)}, \theta^{(j)})) \geq 0
\]</span>   即： <span class="math display">\[
ln \; L(\theta^{(j+1)}) - ln\;L(\theta^{(j)})  \geq 0
\]</span>   所以EM算法是可以逐步收敛到某一极大值附近的。证毕。</p>
<h5 id="五em算法的缺陷">五、EM算法的缺陷</h5>
<p>  EM算法是处理含有隐藏变量模型的重要算法，但是EM算法也有其缺陷，首先，EM算法对初始值敏感，不同的初始值可能会导致不同的结果，这是由于似然函数的性质决定的，如果一个似然函数是凹函数，那么最后会收敛到极大值附近，也就是最大值附近，但是如果函数存在多个极大值，那么算法的初始值就会影响最后的结果。</p>

        </div>
        
            <ul class="post-copyright">
            <li><strong>本文标题：</strong><a href="http://huaxuan0720.github.io/2019/05/10/Note2-EM-Algorithm/">EM算法</a></li>
            <li><strong>本文作者：</strong><a href="http://huaxuan0720.github.io">Da Vinci</a></li>
            <li><strong>本文链接：</strong><a href="http://huaxuan0720.github.io/2019/05/10/Note2-EM-Algorithm/">http://huaxuan0720.github.io/2019/05/10/Note2-EM-Algorithm/</a></li>
            <li><strong>发布时间：</strong>2019-05-10</li>
            <li><strong>版权声明：</strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="external nofollow" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明出处！
            </li>
            </ul>
        
        
        <hr style="height:1px;margin:1rem 0">
        <div class="level is-size-7 is-uppercase">
            <div class="level-start">
                <div class="level-item">
                    <i class="fas fa-tags has-text-grey"></i>&nbsp;
                    <a class="has-link-grey -link" href="/tags/EM算法/">EM算法</a>,&nbsp;<a class="has-link-grey -link" href="/tags/机器学习/">机器学习</a>
                </div>
            </div>
        </div>
        
        
        
    </div>
</div>



<div class="card">
    <div class="card-content">
        <h3 class="menu-label has-text-centered">Like this article? Support the author with</h3>
        <div class="buttons is-centered">
            
                
<a class="button is-info donate">
    <span class="icon is-small">
        <i class="fab fa-alipay"></i>
    </span>
    <span>Alipay</span>
    <div class="qrcode"><img src="/images/alipay.jpg" alt="Alipay"></div>
</a>

                
                
<a class="button is-success donate">
    <span class="icon is-small">
        <i class="fab fa-weixin"></i>
    </span>
    <span>Wechat</span>
    <div class="qrcode"><img src="/images/wechat.jpg" alt="Wechat"></div>
</a>

                
        </div>
    </div>
</div>



<div class="card card-transparent">
    <div class="level post-navigation is-flex-wrap is-mobile">
        
        <div class="level-start">
            <a class="level level-item has-link-grey  article-nav-prev" href="/2019/05/10/Note3-Logic-Regression/">
                <i class="level-item fas fa-chevron-left"></i>
                <span class="level-item">逻辑回归算法</span>
            </a>
        </div>
        
        
        <div class="level-end">
            <a class="level level-item has-link-grey  article-nav-next" href="/2019/05/10/Note1-AdaBoost/">
                <span class="level-item">Adaboost算法</span>
                <i class="level-item fas fa-chevron-right"></i>
            </a>
        </div>
        
    </div>
</div>



<div class="card">
    <div class="card-content">
        <h3 class="title is-5 has-text-weight-normal">Comments</h3>
        
<div id="valine-thread" class="content"></div>
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="//unpkg.com/valine/dist/Valine.min.js"></script>
<script>
    new Valine({
        el: '#valine-thread' ,
        notify: true,
        verify: false,
        app_id: 'iccwxYBr9y70NgcI4taslyB9-gzGzoHsz',
        app_key: 'ksGgGN0AeLXQQ1HfOy0mCrM0',
        placeholder: 'xxxxxxxx'
    });
</script>

    </div>
</div>

</div>
                




<div class="column is-4-tablet is-4-desktop is-3-widescreen  has-order-1 column-left ">
    
        
<div class="card widget">
    <div class="card-content">
        <nav class="level" style="margin-bottom:1rem">
            <div class="level-item has-text-centered">
                <div>
                    
                        <img class="image is-96x96 has-mb-6" src="/images/icon.jpg" alt="Da Vinci">
                    
                    
                    <p class="is-size-4 is-block">
                        Da Vinci
                    </p>
                    
                    
                    <p class="is-size-6 is-block">
                        A Student
                    </p>
                    
                    
                    <p class="is-size-6 is-flex is-flex-center has-text-grey">
                        <i class="fas fa-map-marker-alt has-mr-7"></i>
                        <span>Hangzhou Zhejiang, China</span>
                    </p>
                    
                </div>
            </div>
        </nav>
        <nav class="level menu-list is-mobile" style="margin-bottom:1rem">
            <div class="level-item has-text-centered is-marginless">
                <a href="/archives/">
                    <p class="heading">
                        Posts
                    </p>
                    <p class="title has-text-weight-normal">
                        27
                    </p>
                </a>
            </div>
            <div class="level-item has-text-centered is-marginless">
                <a href="/categories/">
                    <p class="heading">
                        Categories
                    </p>
                    <p class="title has-text-weight-normal">
                        3
                    </p>
                </a>
            </div>
            <div class="level-item has-text-centered is-marginless">
                <a href="/tags/">
                    <p class="heading">
                        Tags
                    </p>
                    <p class="title has-text-weight-normal">
                        21
                    </p>
                </a>
            </div>
        </nav>
        <div class="level">
            <a class="level-item button is-link is-rounded" href="https://github.com/huaxuan0720" target="_blank">
                <i class="fab fa-github"></i>&nbsp;&nbsp;Follow</a>
        </div>
        
        
        <div class="level is-mobile">
            
            <a class="level-item button is-white is-marginless" target="_blank" title="Github" href="https://github.com/huaxuan0720">
                
                <i class="fab fa-github"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank" title="Facebook" href="/">
                
                <i class="fab fa-facebook"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank" title="Twitter" href="/">
                
                <i class="fab fa-twitter"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank" title="RSS" href="/">
                
                <i class="fas fa-rss"></i>
                
            </a>
            
        </div>
        
    </div>
</div>

    
        
<div class="card widget column-left is-sticky" id="toc">
    <div class="card-content">
        <div class="menu">
            <h3 class="menu-label">
                Catalogue
            </h3>
            <ul class="menu-list"><li>
        <a class="is-flex" href="#前言">
        <span class="has-mr-6">1</span>
        <span>前言</span>
        </a></li><li>
        <a class="is-flex" href="#一准备工作">
        <span class="has-mr-6">2</span>
        <span>一、准备工作</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#极大似然估计">
        <span class="has-mr-6">2.1</span>
        <span>1、极大似然估计</span>
        </a></li><li>
        <a class="is-flex" href="#jensen不等式">
        <span class="has-mr-6">2.2</span>
        <span>2、Jensen不等式</span>
        </a></li><li>
        <a class="is-flex" href="#边缘分布">
        <span class="has-mr-6">2.3</span>
        <span>3、边缘分布</span>
        </a></li></ul></li><li>
        <a class="is-flex" href="#二em算法">
        <span class="has-mr-6">3</span>
        <span>二、EM算法</span>
        </a></li><li>
        <a class="is-flex" href="#三em算法解决三硬币模型">
        <span class="has-mr-6">4</span>
        <span>三、EM算法解决三硬币模型</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#构造极大似然函数">
        <span class="has-mr-6">4.1</span>
        <span>构造极大似然函数</span>
        </a></li><li>
        <a class="is-flex" href="#构造我们的q函数">
        <span class="has-mr-6">4.2</span>
        <span>构造我们的Q函数</span>
        </a></li><li>
        <a class="is-flex" href="#求解极大值">
        <span class="has-mr-6">4.3</span>
        <span>求解极大值</span>
        </a></li></ul></li><li>
        <a class="is-flex" href="#四em算法的收敛性">
        <span class="has-mr-6">5</span>
        <span>四、EM算法的收敛性</span>
        </a></li><li>
        <a class="is-flex" href="#五em算法的缺陷">
        <span class="has-mr-6">6</span>
        <span>五、EM算法的缺陷</span>
        </a></li></ul>
        </div>
    </div>
</div>


    
    
        <div class="column-right-shadow is-hidden-widescreen ">
        
        </div>
    
</div>

                
            </div>
        </div>
    </section>
    <footer class="footer">
    <div class="container">
        <div class="level">
            <div class="level-start has-text-centered-mobile">
                <a class="footer-logo is-block has-mb-6" href="/">
                
                    <img src="/images/favicon.svg" alt="EM算法" height="28">
                
                </a>
                <p class="is-size-7">
                &copy; 2019 Da Vinci&nbsp;
                Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> & <a href="http://github.com/ppoffice/hexo-theme-icarus" target="_blank">Icarus</a>
                
                <br>
                <span id="busuanzi_container_site_uv">
                Visited by <span id="busuanzi_value_site_uv">0</span> users
                </span>
                
                </p>
            </div>
            <div class="level-end">
            
                <div class="field has-addons is-flex-center-mobile has-mt-5-mobile is-flex-wrap is-flex-middle">
                
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" title="CC BY-NC-SA 4.0" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">
                        
                        <i class="fab fa-creative-commons"></i>&nbsp;<i class="fab fa-creative-commons-by"></i>&nbsp;<i class="fab fa-creative-commons-nc"></i>&nbsp;<i class="fab fa-creative-commons-sa"></i>&nbsp;
                        
                    </a>
                </p>
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" title="Xuan Hua&#39;s GitHub" href="https://www.github.com/huaxuan0720">
                        
                        <i class="fab fa-github"></i>&nbsp;
                        
                    </a>
                </p>
                
                </div>
            
            </div>
        </div>
    </div>
</footer>

    <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script>
<script>moment.locale("en");</script>


    
    
    
    <script src="/js/animation.js"></script>
    

    
    
    
    <script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script>
    <script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script>
    <script src="/js/gallery.js" defer></script>
    

    
    

<div id="outdated">
    <h6>Your browser is out-of-date!</h6>
    <p>Update your browser to view this website correctly. <a id="btnUpdateBrowser" href="http://outdatedbrowser.com/">Update
            my browser now </a></p>
    <p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">&times;</a></p>
</div>
<script src="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.js" defer></script>
<script>
    document.addEventListener("DOMContentLoaded", function () {
        outdatedBrowser({
            bgColor: '#f25648',
            color: '#ffffff',
            lowerThan: 'flex'
        });
    });
</script>


    
    
<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script>
<script>
document.addEventListener('DOMContentLoaded', function () {
    MathJax.Hub.Config({
        'HTML-CSS': {
            matchFontHeight: false
        },
        SVG: {
            matchFontHeight: false
        },
        CommonHTML: {
            matchFontHeight: false
        },
        tex2jax: {
            inlineMath: [
                ['$','$'],
                ['\\(','\\)']
            ]
        }
    });
});
</script>

    
    

<a id="back-to-top" title="Back to Top" href="javascript:;">
    <i class="fas fa-chevron-up"></i>
</a>
<script src="/js/back-to-top.js" defer></script>


    
    

    
    
    
    

    
    
    
    
    
    <script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script>
    <script src="/js/clipboard.js" defer></script>
    

    
    
    

    


<script src="/js/main.js" defer></script>

    
    <div class="searchbox ins-search">
    <div class="searchbox-container ins-search-container">
        <div class="searchbox-input-wrapper">
            <input type="text" class="searchbox-input ins-search-input" placeholder="Type something...">
            <span class="searchbox-close ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="searchbox-result-wrapper ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
    (function (window) {
        var INSIGHT_CONFIG = {
            TRANSLATION: {
                POSTS: 'Posts',
                PAGES: 'Pages',
                CATEGORIES: 'Categories',
                TAGS: 'Tags',
                UNTITLED: '(Untitled)',
            },
            CONTENT_URL: '/content.json',
        };
        window.INSIGHT_CONFIG = INSIGHT_CONFIG;
    })(window);
</script>
<script src="/js/insight.js" defer></script>
<link rel="stylesheet" href="/css/search.css">
<link rel="stylesheet" href="/css/insight.css">
    
</body>
</html>