<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
    <meta charset="utf-8">
<title>步长stride为s的二维卷积方法的反向传播算法：一个十分极端的例子 - Welcome to My Blogs</title>
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">



    <meta name="description" content="前言&amp;emsp;&amp;emsp;在前面的文章中，介绍了二维平面上的卷积及其反向传播的算法，但是，步长为1和2毕竟都是两个比较小的数字，如果换成更大的数字，反向传播的方式是不是还适合呢？所以，我们考虑下面这个十分极端的例子，来验证反向传播算法的有效性。">
<meta name="keywords" content="深度学习,反向传播,卷积">
<meta property="og:type" content="article">
<meta property="og:title" content="步长stride为s的二维卷积方法的反向传播算法：一个十分极端的例子">
<meta property="og:url" content="http://huaxuan0720.github.io/2019/05/24/Note16-ConvBackProp-part3/index.html">
<meta property="og:site_name" content="Welcome to My Blogs">
<meta property="og:description" content="前言&amp;emsp;&amp;emsp;在前面的文章中，介绍了二维平面上的卷积及其反向传播的算法，但是，步长为1和2毕竟都是两个比较小的数字，如果换成更大的数字，反向传播的方式是不是还适合呢？所以，我们考虑下面这个十分极端的例子，来验证反向传播算法的有效性。">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://huaxuan0720.github.io/gallery/DeepLearning.jpg">
<meta property="og:updated_time" content="2019-05-27T06:38:28.891Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="步长stride为s的二维卷积方法的反向传播算法：一个十分极端的例子">
<meta name="twitter:description" content="前言&amp;emsp;&amp;emsp;在前面的文章中，介绍了二维平面上的卷积及其反向传播的算法，但是，步长为1和2毕竟都是两个比较小的数字，如果换成更大的数字，反向传播的方式是不是还适合呢？所以，我们考虑下面这个十分极端的例子，来验证反向传播算法的有效性。">
<meta name="twitter:image" content="http://huaxuan0720.github.io/gallery/DeepLearning.jpg">







<link rel="icon" href="/images/favicon.svg">


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.7.2/css/bulma.css">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.4.1/css/all.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:400,600|Source+Code+Pro">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/github-gist.css">


    
    
    
    <style>body>.footer,body>.navbar,body>.section{opacity:0}</style>
    

    
    
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css">
    

    
    

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.css">


    
    
    
    

<link rel="stylesheet" href="/css/back-to-top.css">


    
    

    
    
    
    

    
    
<link rel="stylesheet" href="/css/progressbar.css">
<script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>

    
    
    

    
    
    
        <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    

    


<link rel="stylesheet" href="/css/style.css">
</head>
<body class="is-3-column">
    <nav class="navbar navbar-main">
    <div class="container">
        <div class="navbar-brand is-flex-center">
            <a class="navbar-item navbar-logo" href="/">
            
                <img src="/images/favicon.svg" alt="步长stride为s的二维卷积方法的反向传播算法：一个十分极端的例子" height="28">
            
            </a>
        </div>
        <div class="navbar-menu">
            
            <div class="navbar-start">
                
                <a class="navbar-item" href="/">主页</a>
                
                <a class="navbar-item" href="/archives/">归档</a>
                
                <a class="navbar-item" href="/categories/">类别</a>
                
                <a class="navbar-item" href="/tags/">标签</a>
                
                <a class="navbar-item" href="/about/">关于</a>
                
            </div>
            
            <div class="navbar-end">
                
                    
                    
                    <a class="navbar-item" target="_blank" title="Xuan Hua&#39;s GitHub" href="https://www.github.com/huaxuan0720">
                        
                        <i class="fab fa-github"></i>
                        
                    </a>
                    
                
                
                <a class="navbar-item is-hidden-tablet catalogue" title="Catálogo" href="javascript:;">
                    <i class="fas fa-list-ul"></i>
                </a>
                
                
                <a class="navbar-item search" title="Search" href="javascript:;">
                    <i class="fas fa-search"></i>
                </a>
                
            </div>
        </div>
    </div>
</nav>
    
    <section class="section">
        <div class="container">
            <div class="columns">
                <div class="column is-8-tablet is-8-desktop is-9-widescreen has-order-2 column-main"><div class="card">
    
    <div class="card-image">
        <span class="image is-7by1">
            <img class="thumbnail" src="/gallery/DeepLearning.jpg" alt="步长stride为s的二维卷积方法的反向传播算法：一个十分极端的例子">
        </span>
    </div>
    
    <div class="card-content article ">
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <i class="fas fa-angle-double-right"></i>步长stride为s的二维卷积方法的反向传播算法：一个十分极端的例子
            
        </h1>
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2019-05-24T04:32:45.000Z"><i class="far fa-calendar-alt">&nbsp;</i>2019-05-24</time>
                
                <time class="level-item has-text-grey is-hidden-mobile" datetime="2019-05-27T06:38:28.891Z"><i class="far fa-calendar-check">&nbsp;</i>2019-05-27</time>
                
                
                <div class="level-item">
                <i class="far fa-folder-open has-text-grey"></i>&nbsp;
                <a class="has-link-grey -link" href="/categories/深度学习/">深度学习</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    <i class="far fa-clock"></i>&nbsp;
                    
                    
                    19 minutes read (About 2794 words)
                </span>
                
                
                <span class="level-item has-text-grey" id="busuanzi_container_page_pv">
                    <i class="far fa-eye"></i>
                    <span id="busuanzi_value_page_pv">0</span> visits
                </span>
                
            </div>
        </div>
        
        <div class="content">
            <h5 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h5><p>&emsp;&emsp;在前面的文章中，介绍了二维平面上的卷积及其反向传播的算法，但是，步长为1和2毕竟都是两个比较小的数字，如果换成更大的数字，反向传播的方式是不是还适合呢？所以，我们考虑下面这个十分极端的例子，来验证反向传播算法的有效性。  </p>
<a id="more"></a>

<h5 id="一、参数设置"><a href="#一、参数设置" class="headerlink" title="一、参数设置"></a>一、参数设置</h5><p>&emsp;&emsp;在之前的参数设置中，我们使用的输入矩阵都是5x5，在这篇文章中，我们使用10x10大小的矩阵，在卷积核方面，我们依然使用3x3大小的卷积核，步长stride方面，我们使用一个很大的数字7，padding方式依然设置为VALID。  </p>
<p>&emsp;&emsp;因此，我们的参数汇总如下：  </p>
<table>
<thead>
<tr>
<th>参数</th>
<th>设置</th>
</tr>
</thead>
<tbody><tr>
<td>输入矩阵$x$</td>
<td>一个二维矩阵，大小为10x10</td>
</tr>
<tr>
<td>输入卷积核$k$</td>
<td>一个二维矩阵，大小为3x3</td>
</tr>
<tr>
<td>步长$stride$</td>
<td>设置为7</td>
</tr>
<tr>
<td>padding</td>
<td>VALID</td>
</tr>
<tr>
<td>偏置项$b$</td>
<td>一个浮点数</td>
</tr>
</tbody></table>
<p>&emsp;&emsp;和前面一样，我们定义卷积操作的符号为$conv$，我们可以将卷积表示为（需要注意的是这里步长选取为<strong>7</strong>）：<br>$$<br>x ; conv ; k + b = u<br>$$<br>&emsp;&emsp;展开之后，我们可以得到：<br>$$<br>\begin{bmatrix}<br>x_{1, 1} &amp; x_{1, 2} &amp; x_{1, 3} &amp;x_{1, 4} &amp;x_{1, 5} &amp; x_{1, 6} &amp; x_{1, 7} &amp; x_{1, 8} &amp;x_{1, 9} &amp;x_{1, 10}  \<br>x_{2, 1} &amp; x_{2, 2} &amp; x_{2, 3} &amp;x_{2, 4} &amp;x_{2, 5} &amp; x_{2, 6} &amp; x_{2, 7} &amp; x_{2, 8} &amp;x_{2, 9} &amp;x_{2, 10}  \<br>x_{3, 1} &amp; x_{3, 2} &amp; x_{3, 3} &amp;x_{3, 4} &amp;x_{3, 5} &amp; x_{3, 6} &amp; x_{3, 7} &amp; x_{3, 8} &amp;x_{3, 9} &amp;x_{3, 10}  \<br>x_{4, 1} &amp; x_{4, 2} &amp; x_{4, 3} &amp;x_{4, 4} &amp;x_{4, 5} &amp; x_{4, 6} &amp; x_{4, 7} &amp; x_{4, 8} &amp;x_{4, 9} &amp;x_{4, 10}  \<br>x_{5, 1} &amp; x_{5, 2} &amp; x_{5, 3} &amp;x_{5, 4} &amp;x_{5, 5} &amp; x_{5, 6} &amp; x_{5, 7} &amp; x_{5, 8} &amp;x_{5, 9} &amp;x_{5, 10}  \<br>x_{6, 1} &amp; x_{6, 2} &amp; x_{6, 3} &amp;x_{6, 4} &amp;x_{6, 5} &amp; x_{6, 6} &amp; x_{6, 7} &amp; x_{6, 8} &amp;x_{6, 9} &amp;x_{6, 10}  \<br>x_{7, 1} &amp; x_{7, 2} &amp; x_{7, 3} &amp;x_{7, 4} &amp;x_{7, 5} &amp; x_{7, 6} &amp; x_{7, 7} &amp; x_{7, 8} &amp;x_{7, 9} &amp;x_{7, 10}  \<br>x_{8, 1} &amp; x_{8, 2} &amp; x_{8, 3} &amp;x_{8, 4} &amp;x_{8, 5} &amp; x_{8, 6} &amp; x_{8, 7} &amp; x_{8, 8} &amp;x_{8, 9} &amp;x_{8, 10}  \<br>x_{9, 1} &amp; x_{9, 2} &amp; x_{9, 3} &amp;x_{9, 4} &amp;x_{9, 5} &amp; x_{9, 6} &amp; x_{9, 7} &amp; x_{9, 8} &amp;x_{9, 9} &amp;x_{9, 10}  \<br>x_{10, 1} &amp; x_{10, 2} &amp; x_{10, 3} &amp;x_{10, 4} &amp;x_{10, 5} &amp; x_{10, 6} &amp; x_{10, 7} &amp; x_{10, 8} &amp;x_{10, 9} &amp;x_{10, 10}  \<br>\end{bmatrix} ; conv ;<br>\begin{bmatrix}<br>k_{1, 1} &amp; k_{1, 2} &amp; k_{1, 3}\<br>k_{2, 1} &amp; k_{2, 2} &amp; k_{2, 3}\<br>k_{3, 1} &amp; k_{3, 2} &amp; k_{3, 3}\<br>\end{bmatrix} + b =<br>\begin{bmatrix}<br>u_{1, 1} &amp; u_{1, 2} \<br>u_{2, 1} &amp; u_{2, 2} \<br>\end{bmatrix}<br>$$<br>将矩阵$u$进一步展开，我们有：<br>$$<br>\begin{bmatrix}<br>u_{1, 1} &amp; u_{1, 2} \<br>u_{2, 1} &amp; u_{2, 2} \<br>\end{bmatrix} = \<br>\begin{bmatrix}<br>\begin{matrix}<br>x_{1, 1}k_{1, 1} + x_{1, 2}k_{1, 2} +x_{1, 3}k_{1, 3} + \<br>x_{2, 1}k_{2, 1} + x_{2, 2}k_{2, 2} +x_{2, 3}k_{2, 3} + \<br>x_{3, 1}k_{3, 1} + x_{3, 2}k_{3, 2} +x_{3, 3}k_{3, 3} + b \<br>\end{matrix} &amp; \begin{matrix}<br>x_{1, 8}k_{1, 1} + x_{1, 9}k_{1, 2} +x_{1, 10}k_{1, 3} + \<br>x_{2, 8}k_{2, 1} + x_{2, 9}k_{2, 2} +x_{2, 10}k_{2, 3} + \<br>x_{3, 8}k_{3, 1} + x_{3, 9}k_{3, 2} +x_{3, 10}k_{3, 3} + b \<br>\end{matrix} \ \<br>\begin{matrix}<br>x_{8, 1}k_{1, 1} + x_{8, 2}k_{1, 2} +x_{8, 3}k_{1, 3} + \<br>x_{9, 1}k_{2, 1} + x_{9, 2}k_{2, 2} +x_{9, 3}k_{2, 3} + \<br>x_{10, 1}k_{3, 1} + x_{10, 2}k_{3, 2} +x_{10, 3}k_{3, 3} + b \<br>\end{matrix} &amp; \begin{matrix}<br>x_{8, 8}k_{1, 1} + x_{8, 9}k_{1, 2} +x_{8, 10}k_{1, 3} + \<br>x_{9, 8}k_{2, 1} + x_{9, 9}k_{2, 2} +x_{9, 10}k_{2, 3} + \<br>x_{10, 8}k_{3, 1} + x_{10, 9}k_{3, 2} +x_{10, 10}k_{3, 3} + b \<br>\end{matrix} \<br>\end{bmatrix}<br>$$</p>
<h5 id="二、误差传递"><a href="#二、误差传递" class="headerlink" title="二、误差传递"></a>二、误差传递</h5><p>&emsp;&emsp;和之前一样，为了方便计算，也为了方便观察，我们计算如下的表格，每一列表示的是一个特定的输出 $\partial u_{i, j}$，每一行表示的是一个特定的输入值$\partial x_{p, k}$，行与列相交的地方表示的就是二者相除的结果，表示的是输出对于输入的偏导数，即$\frac{\partial u_{i, j}}{\partial x_{p, k}}$。最后一列显示的是计算出的需要传递的误差的偏导数，具体计算方法和前面一样，在这里不再赘述：</p>
<table>
<thead>
<tr>
<th></th>
<th align="center">$\partial u_{1, 1}$</th>
<th align="center">$\partial u_{1, 2}$</th>
<th align="center">$\partial u_{2, 1}$</th>
<th align="center">$\partial u_{2, 2}$</th>
<th align="left">$\frac{\partial L}{\partial x_{i, j}}$</th>
</tr>
</thead>
<tbody><tr>
<td>$\partial x_{1, 1}$</td>
<td align="center">$k_{1, 1}$</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="left">$\frac{\partial L}{\partial x_{1, 1}} = \delta_{1, 1} k_{1, 1}$</td>
</tr>
<tr>
<td>$\partial x_{1, 2}$</td>
<td align="center">$k_{1, 2}$</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="left">$\frac{\partial L}{\partial x_{1, 2}} = \delta_{1, 1} k_{1, 2}$</td>
</tr>
<tr>
<td>$\partial x_{1, 3}$</td>
<td align="center">$k_{1, 3}$</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="left">$\frac{\partial L}{\partial x_{1, 3}} = \delta_{1, 1} k_{1, 3}$</td>
</tr>
<tr>
<td>$\partial x_{1, 8}$</td>
<td align="center">0</td>
<td align="center">$k_{1, 1}$</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="left">$\frac{\partial L}{\partial x_{1, 8}} = \delta_{1, 2}k_{1, 1}$</td>
</tr>
<tr>
<td>$\partial x_{1, 9}$</td>
<td align="center">0</td>
<td align="center">$k_{1, 2}$</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="left">$\frac{\partial L}{\partial x_{1, 9}} = \delta_{1, 2}k_{1, 2}$</td>
</tr>
<tr>
<td>$\partial x_{1, 10}$</td>
<td align="center">0</td>
<td align="center">$k_{1, 3}$</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="left">$\frac{\partial L}{\partial x_{1, 10}} = \delta_{1, 2}k_{1, 3}$</td>
</tr>
<tr>
<td>$\partial x_{2, 1}$</td>
<td align="center">$k_{2, 1}$</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="left">$\frac{\partial L}{\partial x_{2, 1}} = \delta_{1, 1} k_{2, 1}$</td>
</tr>
<tr>
<td>$\partial x_{2, 2}$</td>
<td align="center">$k_{2, 2}$</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="left">$\frac{\partial L}{\partial x_{2, 2}} = \delta_{1, 1} k_{2, 2}$</td>
</tr>
<tr>
<td>$\partial x_{2, 3}$</td>
<td align="center">$k_{2, 3}$</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="left">$\frac{\partial L}{\partial x_{2, 3}} = \delta_{1, 1} k_{2, 3}$</td>
</tr>
<tr>
<td>$\partial x_{2, 8}$</td>
<td align="center">0</td>
<td align="center">$k_{2, 1}$</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="left">$\frac{\partial L}{\partial x_{2, 8}} = \delta_{1, 2}k_{2, 1}$</td>
</tr>
<tr>
<td>$\partial x_{2, 9}$</td>
<td align="center">0</td>
<td align="center">$k_{2, 2}$</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="left">$\frac{\partial L}{\partial x_{2, 9}} = \delta_{1, 2}k_{2, 2}$</td>
</tr>
<tr>
<td>$\partial x_{2, 10}$</td>
<td align="center">0</td>
<td align="center">$k_{2, 3}$</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="left">$\frac{\partial L}{\partial x_{2, 10}} = \delta_{1, 2}k_{2, 3}$</td>
</tr>
<tr>
<td>$\partial x_{3, 1}$</td>
<td align="center">$k_{3, 1}$</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="left">$\frac{\partial L}{\partial x_{3, 1}} = \delta_{1, 1} k_{3, 1}$</td>
</tr>
<tr>
<td>$\partial x_{3, 2}$</td>
<td align="center">$k_{3, 2}$</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="left">$\frac{\partial L}{\partial x_{3, 2}} = \delta_{1, 1} k_{3, 2}$</td>
</tr>
<tr>
<td>$\partial x_{3, 3}$</td>
<td align="center">$k_{3, 3}$</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="left">$\frac{\partial L}{\partial x_{3, 3}} = \delta_{1, 1} k_{3, 3}$</td>
</tr>
<tr>
<td>$\partial x_{3, 8}$</td>
<td align="center">0</td>
<td align="center">$k_{3, 1}$</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="left">$\frac{\partial L}{\partial x_{3, 8}} = \delta_{1, 2}k_{3, 1}$</td>
</tr>
<tr>
<td>$\partial x_{3, 9}$</td>
<td align="center">0</td>
<td align="center">$k_{3, 2}$</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="left">$\frac{\partial L}{\partial x_{3, 9}} = \delta_{1, 2}k_{3, 2}$</td>
</tr>
<tr>
<td>$\partial x_{3, 10}$</td>
<td align="center">0</td>
<td align="center">$k_{3, 3}$</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="left">$\frac{\partial L}{\partial x_{3, 10}} = \delta_{1, 2}k_{3, 3}$</td>
</tr>
<tr>
<td>$\partial x_{8, 1}$</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">$k_{1, 1}$</td>
<td align="center">0</td>
<td align="left">$\frac{\partial L}{\partial x_{8, 1}} = \delta_{2, 1} k_{1, 1}$</td>
</tr>
<tr>
<td>$\partial x_{8, 2}$</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">$k_{1, 2}$</td>
<td align="center">0</td>
<td align="left">$\frac{\partial L}{\partial x_{8, 2}} = \delta_{2, 1} k_{1, 2}$</td>
</tr>
<tr>
<td>$\partial x_{8, 3}$</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">$k_{1, 3}$</td>
<td align="center">0</td>
<td align="left">$\frac{\partial L}{\partial x_{8, 3}} = \delta_{2, 1} k_{1, 3}$</td>
</tr>
<tr>
<td>$\partial x_{8, 8}$</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">$k_{1, 1}$</td>
<td align="left">$\frac{\partial L}{\partial x_{8, 8}} = \delta_{2, 2}k_{1, 1}$</td>
</tr>
<tr>
<td>$\partial x_{8, 9}$</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">$k_{1, 2}$</td>
<td align="left">$\frac{\partial L}{\partial x_{8, 9}} = \delta_{2, 2}k_{1, 2}$</td>
</tr>
<tr>
<td>$\partial x_{8, 10}$</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">$k_{1, 3}$</td>
<td align="left">$\frac{\partial L}{\partial x_{8, 10}} = \delta_{2, 2}k_{1, 3}$</td>
</tr>
<tr>
<td>$\partial x_{9, 1}$</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">$k_{2, 1}$</td>
<td align="center">0</td>
<td align="left">$\frac{\partial L}{\partial x_{9, 1}} = \delta_{2, 1} k_{2, 1}$</td>
</tr>
<tr>
<td>$\partial x_{9, 2}$</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">$k_{2, 2}$</td>
<td align="center">0</td>
<td align="left">$\frac{\partial L}{\partial x_{9, 2}} = \delta_{2, 1} k_{2, 2}$</td>
</tr>
<tr>
<td>$\partial x_{9, 3}$</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">$k_{2, 3}$</td>
<td align="center">0</td>
<td align="left">$\frac{\partial L}{\partial x_{9, 3}} = \delta_{2, 1} k_{2, 3}$</td>
</tr>
<tr>
<td>$\partial x_{9, 8}$</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">$k_{2, 1}$</td>
<td align="left">$\frac{\partial L}{\partial x_{9, 8}} = \delta_{2, 2}k_{2, 1}$</td>
</tr>
<tr>
<td>$\partial x_{9, 9}$</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">$k_{2, 2}$</td>
<td align="left">$\frac{\partial L}{\partial x_{9, 9}} = \delta_{2, 2}k_{2, 2}$</td>
</tr>
<tr>
<td>$\partial x_{9, 10}$</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">$k_{2, 3}$</td>
<td align="left">$\frac{\partial L}{\partial x_{9, 10}} = \delta_{2, 2}k_{2, 3}$</td>
</tr>
<tr>
<td>$\partial x_{10, 1}$</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">$k_{3, 1}$</td>
<td align="center">0</td>
<td align="left">$\frac{\partial L}{\partial x_{10, 1}} = \delta_{2, 1} k_{3, 1}$</td>
</tr>
<tr>
<td>$\partial x_{10, 2}$</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">$k_{3, 2}$</td>
<td align="center">0</td>
<td align="left">$\frac{\partial L}{\partial x_{10, 2}} = \delta_{2, 1} k_{3, 2}$</td>
</tr>
<tr>
<td>$\partial x_{10, 3}$</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">$k_{3, 3}$</td>
<td align="center">0</td>
<td align="left">$\frac{\partial L}{\partial x_{10, 3}} = \delta_{2, 1} k_{3, 3}$</td>
</tr>
<tr>
<td>$\partial x_{10, 8}$</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">$k_{3, 1}$</td>
<td align="left">$\frac{\partial L}{\partial x_{10, 8}} = \delta_{2, 2}k_{3, 1}$</td>
</tr>
<tr>
<td>$\partial x_{10, 9}$</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">$k_{3, 2}$</td>
<td align="left">$\frac{\partial L}{\partial x_{10, 9}} = \delta_{2, 2}k_{3, 2}$</td>
</tr>
<tr>
<td>$\partial x_{10, 10}$</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">$k_{3, 3}$</td>
<td align="left">$\frac{\partial L}{\partial x_{10, 10}} = \delta_{2, 2}k_{3, 3}$</td>
</tr>
<tr>
<td>$else$</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="left">0</td>
</tr>
</tbody></table>
<p>&emsp;&emsp;可以看出，无论是何种卷积方式，数据都是十分有规律地进行分布。  </p>
<p>&emsp;&emsp;我们假设后面传递过来的误差是 $\delta$ ，即：<br>$$<br>\delta =<br>\begin{bmatrix}<br>\delta_{1, 1} &amp; \delta_{1, 2} \<br>\delta_{2, 1} &amp; \delta_{2, 2} \<br>\end{bmatrix}<br>$$<br>&emsp;&emsp;其中，$\delta_{i, j} = \frac{\partial L}{\partial u_{i, j}}$，误差分别对应于每一个输出项。这里的$L$表示的是最后的Loss损失。我们的目的就是希望这个损失尽可能小。  </p>
<p>&emsp;&emsp;根据前面的方法，我们先要求应该传递给下一层的误差。所以第一步，我们先在接受来的误差矩阵中插入合适数目的0，由于这里前向卷积采用的步长stride是7，所以接收到误差矩阵中的每个元素之间应该插入（7 - 1 = 6）个0，即：<br>$$<br>\begin{bmatrix}<br>\delta_{1, 1} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \delta_{1, 2} \<br> 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \<br> 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \<br> 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \<br> 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \<br> 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \<br> 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \<br>\delta_{2, 1} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \delta_{2, 2} \<br>\end{bmatrix}<br>$$<br>&emsp;&emsp;接着，由于我们采用的卷积核的大小是3x3，所有，我们依然需要在上面矩阵的外围补上（3 - 1 = 2）层0，即：<br>$$<br>\begin{bmatrix}<br>0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \<br>0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \<br>0 &amp; 0 &amp; \delta_{1, 1} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \delta_{1, 2}  &amp; 0 &amp; 0 \<br>0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \<br>0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \<br>0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \<br>0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \<br>0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \<br>0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \<br>0 &amp; 0 &amp; \delta_{2, 1} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \delta_{2, 2}  &amp; 0 &amp; 0 \<br>0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \<br>0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \<br>\end{bmatrix}<br>$$<br>&emsp;&emsp;下一步就是将正向卷积的卷积核旋转180°，即：<br>$$<br>\begin{bmatrix}<br>k_{3, 3} &amp; k_{3, 2} &amp; k_{3, 1} \<br>k_{2, 3} &amp; k_{2, 2} &amp; k_{2, 1} \<br>k_{1, 3} &amp; k_{1, 2} &amp; k_{1, 1} \<br>\end{bmatrix}<br>$$<br>&emsp;&emsp;最后一步就是将上面的误差矩阵和旋转后的卷积核进行步长为1的卷积，即：<br>$$<br>\begin{bmatrix}<br>0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \<br>0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \<br>0 &amp; 0 &amp; \delta_{1, 1} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \delta_{1, 2}  &amp; 0 &amp; 0 \<br>0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \<br>0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \<br>0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \<br>0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \<br>0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \<br>0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \<br>0 &amp; 0 &amp; \delta_{2, 1} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \delta_{2, 2}  &amp; 0 &amp; 0 \<br>0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \<br>0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \<br>\end{bmatrix} ; conv(stride = 1); \begin{bmatrix}<br>k_{3, 3} &amp; k_{3, 2} &amp; k_{3, 1} \<br>k_{2, 3} &amp; k_{2, 2} &amp; k_{2, 1} \<br>k_{1, 3} &amp; k_{1, 2} &amp; k_{1, 1} \<br>\end{bmatrix} = \<br>\begin{bmatrix}<br>\delta_{1, 1} k_{1, 1} &amp;  \delta_{1, 1} k_{1, 2} &amp;  \delta_{1, 1} k_{1, 3} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \delta_{1, 2}k_{1, 1} &amp; \delta_{1, 2}k_{1, 2} &amp; \delta_{1, 2}k_{1, 3} \<br>\delta_{1, 1} k_{2, 1} &amp;  \delta_{1, 1} k_{2, 2} &amp;  \delta_{1, 1} k_{2, 3} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \delta_{1, 2}k_{2, 1} &amp; \delta_{1, 2}k_{2, 2} &amp; \delta_{1, 2}k_{2, 3} \<br>\delta_{1, 1} k_{3, 1} &amp;  \delta_{1, 1} k_{3, 2} &amp;  \delta_{1, 1} k_{3, 3} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \delta_{1, 2}k_{3, 1} &amp; \delta_{1, 2}k_{3, 2} &amp; \delta_{1, 2}k_{3, 3} \<br>0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \<br>0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \<br>0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \<br>0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \<br>\delta_{2, 1} k_{1, 1} &amp;  \delta_{2, 1} k_{1, 2} &amp;  \delta_{2, 1} k_{1, 3} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \delta_{2, 2}k_{1, 1} &amp; \delta_{2, 2}k_{1, 2} &amp; \delta_{2, 2}k_{1, 3} \<br>\delta_{2, 1} k_{2, 1} &amp;  \delta_{2, 1} k_{2, 2} &amp;  \delta_{2, 1} k_{2, 3} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \delta_{2, 2}k_{2, 1} &amp; \delta_{2, 2}k_{2, 2} &amp; \delta_{2, 2}k_{2, 3} \<br>\delta_{2, 1} k_{3, 1} &amp;  \delta_{2, 1} k_{3, 2} &amp;  \delta_{2, 1} k_{3, 3} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \delta_{2, 2}k_{3, 1} &amp; \delta_{2, 2}k_{3, 2} &amp; \delta_{2, 2}k_{3, 3} \<br>\end{bmatrix} = \<br>\begin{bmatrix}<br>\frac{\partial L}{\partial x_{1, 1}} &amp;<br>\frac{\partial L}{\partial x_{1, 2}} &amp;<br>\frac{\partial L}{\partial x_{1, 3}} &amp;<br>\frac{\partial L}{\partial x_{1, 4}} &amp;<br>\frac{\partial L}{\partial x_{1, 5}} &amp;<br>\frac{\partial L}{\partial x_{1, 6}} &amp;<br>\frac{\partial L}{\partial x_{1, 7}} &amp;<br>\frac{\partial L}{\partial x_{1, 8}} &amp;<br>\frac{\partial L}{\partial x_{1, 9}} &amp;<br>\frac{\partial L}{\partial x_{1, 10}} \<br>\frac{\partial L}{\partial x_{2, 1}} &amp;<br>\frac{\partial L}{\partial x_{2, 2}} &amp;<br>\frac{\partial L}{\partial x_{2, 3}} &amp;<br>\frac{\partial L}{\partial x_{2, 4}} &amp;<br>\frac{\partial L}{\partial x_{2, 5}} &amp;<br>\frac{\partial L}{\partial x_{2, 6}} &amp;<br>\frac{\partial L}{\partial x_{2, 7}} &amp;<br>\frac{\partial L}{\partial x_{2, 8}} &amp;<br>\frac{\partial L}{\partial x_{2, 9}} &amp;<br>\frac{\partial L}{\partial x_{2, 10}} \<br>\frac{\partial L}{\partial x_{3, 1}} &amp;<br>\frac{\partial L}{\partial x_{3, 2}} &amp;<br>\frac{\partial L}{\partial x_{3, 3}} &amp;<br>\frac{\partial L}{\partial x_{3, 4}} &amp;<br>\frac{\partial L}{\partial x_{3, 5}} &amp;<br>\frac{\partial L}{\partial x_{3, 6}} &amp;<br>\frac{\partial L}{\partial x_{3, 7}} &amp;<br>\frac{\partial L}{\partial x_{3, 8}} &amp;<br>\frac{\partial L}{\partial x_{3, 9}} &amp;<br>\frac{\partial L}{\partial x_{3, 10}} \<br>\frac{\partial L}{\partial x_{4, 1}} &amp;<br>\frac{\partial L}{\partial x_{4, 2}} &amp;<br>\frac{\partial L}{\partial x_{4, 3}} &amp;<br>\frac{\partial L}{\partial x_{4, 4}} &amp;<br>\frac{\partial L}{\partial x_{4, 5}} &amp;<br>\frac{\partial L}{\partial x_{4, 6}} &amp;<br>\frac{\partial L}{\partial x_{4, 7}} &amp;<br>\frac{\partial L}{\partial x_{4, 8}} &amp;<br>\frac{\partial L}{\partial x_{4, 9}} &amp;<br>\frac{\partial L}{\partial x_{4, 10}} \<br>\frac{\partial L}{\partial x_{5, 1}} &amp;<br>\frac{\partial L}{\partial x_{5, 2}} &amp;<br>\frac{\partial L}{\partial x_{5, 3}} &amp;<br>\frac{\partial L}{\partial x_{5, 4}} &amp;<br>\frac{\partial L}{\partial x_{5, 5}} &amp;<br>\frac{\partial L}{\partial x_{5, 6}} &amp;<br>\frac{\partial L}{\partial x_{5, 7}} &amp;<br>\frac{\partial L}{\partial x_{5, 8}} &amp;<br>\frac{\partial L}{\partial x_{5, 9}} &amp;<br>\frac{\partial L}{\partial x_{5, 10}} \<br>\frac{\partial L}{\partial x_{6, 1}} &amp;<br>\frac{\partial L}{\partial x_{6, 2}} &amp;<br>\frac{\partial L}{\partial x_{6, 3}} &amp;<br>\frac{\partial L}{\partial x_{6, 4}} &amp;<br>\frac{\partial L}{\partial x_{6, 5}} &amp;<br>\frac{\partial L}{\partial x_{6, 6}} &amp;<br>\frac{\partial L}{\partial x_{6, 7}} &amp;<br>\frac{\partial L}{\partial x_{6, 8}} &amp;<br>\frac{\partial L}{\partial x_{6, 9}} &amp;<br>\frac{\partial L}{\partial x_{6, 10}} \<br>\frac{\partial L}{\partial x_{7, 1}} &amp;<br>\frac{\partial L}{\partial x_{7, 2}} &amp;<br>\frac{\partial L}{\partial x_{7, 3}} &amp;<br>\frac{\partial L}{\partial x_{7, 4}} &amp;<br>\frac{\partial L}{\partial x_{7, 5}} &amp;<br>\frac{\partial L}{\partial x_{7, 6}} &amp;<br>\frac{\partial L}{\partial x_{7, 7}} &amp;<br>\frac{\partial L}{\partial x_{7, 8}} &amp;<br>\frac{\partial L}{\partial x_{7, 9}} &amp;<br>\frac{\partial L}{\partial x_{7, 10}} \<br>\frac{\partial L}{\partial x_{8, 1}} &amp;<br>\frac{\partial L}{\partial x_{8, 2}} &amp;<br>\frac{\partial L}{\partial x_{8, 3}} &amp;<br>\frac{\partial L}{\partial x_{8, 4}} &amp;<br>\frac{\partial L}{\partial x_{8, 5}} &amp;<br>\frac{\partial L}{\partial x_{8, 6}} &amp;<br>\frac{\partial L}{\partial x_{8, 7}} &amp;<br>\frac{\partial L}{\partial x_{8, 8}} &amp;<br>\frac{\partial L}{\partial x_{8, 9}} &amp;<br>\frac{\partial L}{\partial x_{8, 10}} \<br>\frac{\partial L}{\partial x_{9, 1}} &amp;<br>\frac{\partial L}{\partial x_{9, 2}} &amp;<br>\frac{\partial L}{\partial x_{9, 3}} &amp;<br>\frac{\partial L}{\partial x_{9, 4}} &amp;<br>\frac{\partial L}{\partial x_{9, 5}} &amp;<br>\frac{\partial L}{\partial x_{9, 6}} &amp;<br>\frac{\partial L}{\partial x_{9, 7}} &amp;<br>\frac{\partial L}{\partial x_{9, 8}} &amp;<br>\frac{\partial L}{\partial x_{9, 9}} &amp;<br>\frac{\partial L}{\partial x_{9, 10}} \<br>\frac{\partial L}{\partial x_{10, 1}} &amp;<br>\frac{\partial L}{\partial x_{10, 2}} &amp;<br>\frac{\partial L}{\partial x_{10, 3}} &amp;<br>\frac{\partial L}{\partial x_{10, 4}} &amp;<br>\frac{\partial L}{\partial x_{10, 5}} &amp;<br>\frac{\partial L}{\partial x_{10, 6}} &amp;<br>\frac{\partial L}{\partial x_{10, 7}} &amp;<br>\frac{\partial L}{\partial x_{10, 8}} &amp;<br>\frac{\partial L}{\partial x_{10, 9}} &amp;<br>\frac{\partial L}{\partial x_{10, 10}} \<br>\end{bmatrix}<br>$$</p>
<p>&emsp;&emsp;经过上面的计算，在误差传递上，我们的算法可以正确运行，即使步长stride是一个任意的数字。接下来我们来验证更新梯度的计算。  </p>
<h5 id="三、更新梯度"><a href="#三、更新梯度" class="headerlink" title="三、更新梯度"></a>三、更新梯度</h5><p>&emsp;&emsp;和前面的定义一样，假设我们在这一阶段接收到的后方传递过来的误差为$\delta$， ，即：<br>$$<br>\delta =<br>\begin{bmatrix}<br>\delta_{1, 1} &amp; \delta_{1, 2} \<br>\delta_{2, 1} &amp; \delta_{2, 2} \<br>\end{bmatrix}<br>$$<br>&emsp;&emsp;那么根据偏导数求解的链式法则，我们可以计算出所有的需要的偏导数，这里的计算过程和前面的计算过程是一样的，这里不再赘述。汇总如下：<br>$$<br>\frac{\partial L}{\partial k_{1, 1}} = x_{1, 1}\delta_{1, 1} + x_{1, 8}\delta_{1, 2} + x_{8, 1}\delta_{2, 1} + x_{8, 8}\delta_{2, 2}<br>$$<br>$$<br>\frac{\partial L}{\partial k_{1, 2}} = x_{1, 2}\delta_{1, 1} + x_{1, 9}\delta_{1, 2} + x_{8, 2}\delta_{2, 1} + x_{8, 9}\delta_{2, 2}<br>$$<br>$$<br>\frac{\partial L}{\partial k_{1, 3}} = x_{1, 3}\delta_{1, 1} + x_{1, 10}\delta_{1, 2} + x_{8, 3}\delta_{2, 1} + x_{8, 10}\delta_{2, 2}<br>$$<br>$$<br>\frac{\partial L}{\partial k_{2, 1}} = x_{2, 1}\delta_{1, 1} + x_{2, 8}\delta_{1, 2} + x_{9, 1}\delta_{2, 1} + x_{9, 8}\delta_{2, 2}<br>$$<br>$$<br>\frac{\partial L}{\partial k_{2, 2}} = x_{2, 2}\delta_{1, 1} + x_{2, 9}\delta_{1, 2} + x_{9, 2}\delta_{2, 1} + x_{9, 9}\delta_{2, 2}<br>$$<br>$$<br>\frac{\partial L}{\partial k_{2, 3}} = x_{2, 3}\delta_{1, 1} + x_{2, 10}\delta_{1, 2} + x_{9, 3}\delta_{2, 1} + x_{9, 10}\delta_{2, 2}<br>$$<br>$$<br>\frac{\partial L}{\partial k_{3, 1}} = x_{3, 1}\delta_{1, 1} + x_{3, 8}\delta_{1, 2} + x_{10, 1}\delta_{2, 1} + x_{10, 8}\delta_{2, 2}<br>$$<br>$$<br>\frac{\partial L}{\partial k_{3, 2}} = x_{3, 2}\delta_{1, 1} + x_{3, 9}\delta_{1, 2} + x_{10, 2}\delta_{2, 1} + x_{10, 9}\delta_{2, 2}<br>$$<br>$$<br>\frac{\partial L}{\partial k_{3, 3}} = x_{3, 3}\delta_{1, 1} + x_{3, 10}\delta_{1, 2} + x_{10, 3}\delta_{2, 1} + x_{10, 10}\delta_{2, 2}<br>$$</p>
<p>$$<br>\frac{\partial L}{\partial b} = \delta_{1, 1} + \delta_{1, 2} + \delta_{2, 1} + \delta_{2, 2}<br>$$</p>
<p>&emsp;&emsp;按照之前的算法，由于正向卷积中的步长stride为7，因此，在计算更新梯度的过程中，我们依然需要在接收到的误差矩阵的每两个相邻的元素之间插入（7 - 1 = 6）个0，即：<br>$$<br>\begin{bmatrix}<br>\delta_{1, 1} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \delta_{1, 2} \<br> 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \<br> 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \<br> 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \<br> 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \<br> 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \<br> 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \<br>\delta_{2, 1} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \delta_{2, 2} \<br>\end{bmatrix}<br>$$</p>
<p>&emsp;&emsp;接着我们拿输入矩阵$x$和上面的矩阵进行步长为1的卷积，则可以得到卷积核参数的更新梯度。即：<br>$$<br>\begin{bmatrix}<br>\frac{\partial L}{\partial k_{1, 1}} &amp; \frac{\partial L}{\partial k_{1, 2}} &amp; \frac{\partial L}{\partial k_{1, 3}} \<br>\frac{\partial L}{\partial k_{2, 1}} &amp; \frac{\partial L}{\partial k_{2, 2}} &amp; \frac{\partial L}{\partial k_{2, 3}} \<br>\frac{\partial L}{\partial k_{3, 1}} &amp; \frac{\partial L}{\partial k_{3, 2}} &amp; \frac{\partial L}{\partial k_{3, 3}} \<br>\end{bmatrix} = \<br>\begin{bmatrix}<br>x_{1, 1} &amp; x_{1, 2} &amp; x_{1, 3} &amp;x_{1, 4} &amp;x_{1, 5} &amp; x_{1, 6} &amp; x_{1, 7} &amp; x_{1, 8} &amp;x_{1, 9} &amp;x_{1, 10}  \<br>x_{2, 1} &amp; x_{2, 2} &amp; x_{2, 3} &amp;x_{2, 4} &amp;x_{2, 5} &amp; x_{2, 6} &amp; x_{2, 7} &amp; x_{2, 8} &amp;x_{2, 9} &amp;x_{2, 10}  \<br>x_{3, 1} &amp; x_{3, 2} &amp; x_{3, 3} &amp;x_{3, 4} &amp;x_{3, 5} &amp; x_{3, 6} &amp; x_{3, 7} &amp; x_{3, 8} &amp;x_{3, 9} &amp;x_{3, 10}  \<br>x_{4, 1} &amp; x_{4, 2} &amp; x_{4, 3} &amp;x_{4, 4} &amp;x_{4, 5} &amp; x_{4, 6} &amp; x_{4, 7} &amp; x_{4, 8} &amp;x_{4, 9} &amp;x_{4, 10}  \<br>x_{5, 1} &amp; x_{5, 2} &amp; x_{5, 3} &amp;x_{5, 4} &amp;x_{5, 5} &amp; x_{5, 6} &amp; x_{5, 7} &amp; x_{5, 8} &amp;x_{5, 9} &amp;x_{5, 10}  \<br>x_{6, 1} &amp; x_{6, 2} &amp; x_{6, 3} &amp;x_{6, 4} &amp;x_{6, 5} &amp; x_{6, 6} &amp; x_{6, 7} &amp; x_{6, 8} &amp;x_{6, 9} &amp;x_{6, 10}  \<br>x_{7, 1} &amp; x_{7, 2} &amp; x_{7, 3} &amp;x_{7, 4} &amp;x_{7, 5} &amp; x_{7, 6} &amp; x_{7, 7} &amp; x_{7, 8} &amp;x_{7, 9} &amp;x_{7, 10}  \<br>x_{8, 1} &amp; x_{8, 2} &amp; x_{8, 3} &amp;x_{8, 4} &amp;x_{8, 5} &amp; x_{8, 6} &amp; x_{8, 7} &amp; x_{8, 8} &amp;x_{8, 9} &amp;x_{8, 10}  \<br>x_{9, 1} &amp; x_{9, 2} &amp; x_{9, 3} &amp;x_{9, 4} &amp;x_{9, 5} &amp; x_{9, 6} &amp; x_{9, 7} &amp; x_{9, 8} &amp;x_{9, 9} &amp;x_{9, 10}  \<br>x_{10, 1} &amp; x_{10, 2} &amp; x_{10, 3} &amp;x_{10, 4} &amp;x_{10, 5} &amp; x_{10, 6} &amp; x_{10, 7} &amp; x_{10, 8} &amp;x_{10, 9} &amp;x_{10, 10}  \<br>\end{bmatrix} ; conv(stride = 1); \begin{bmatrix}<br>\delta_{1, 1} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \delta_{1, 2} \<br> 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\<br> 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\<br> 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\<br> 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\<br> 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\<br> 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\<br>\delta_{2, 1} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \delta_{2, 2} \<br>\end{bmatrix}<br>$$</p>
<p>&emsp;&emsp;经过计算，两者的结果是相同的，这也就验证了我们的算法在一些比较极端的情况下也是正确的。  </p>
<h5 id="四、总结"><a href="#四、总结" class="headerlink" title="四、总结"></a>四、总结</h5><p>&emsp;&emsp;经过一个比较极端的卷积实例的讲解，我们验证了我们算法的正确性，而下一步就是用代码实现二维平面上的卷积及其反向传播算法。</p>

        </div>
        
            <ul class="post-copyright">
            <li><strong>本文标题：</strong><a href="http://huaxuan0720.github.io/2019/05/24/Note16-ConvBackProp-part3/">步长stride为s的二维卷积方法的反向传播算法：一个十分极端的例子</a></li>
            <li><strong>本文作者：</strong><a href="http://huaxuan0720.github.io">华轩</a></li>
            <li><strong>本文链接：</strong><a href="http://huaxuan0720.github.io/2019/05/24/Note16-ConvBackProp-part3/">http://huaxuan0720.github.io/2019/05/24/Note16-ConvBackProp-part3/</a></li>
            <li><strong>发布时间：</strong>2019-05-24</li>
            <li><strong>版权声明：</strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="external nofollow" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明出处！
            </li>
            </ul>
        
        
        <hr style="height:1px;margin:1rem 0">
        <div class="level is-size-7 is-uppercase">
            <div class="level-start">
                <div class="level-item">
                    <i class="fas fa-tags has-text-grey"></i>&nbsp;
                    <a class="has-link-grey -link" href="/tags/卷积/">卷积</a>,&nbsp;<a class="has-link-grey -link" href="/tags/反向传播/">反向传播</a>,&nbsp;<a class="has-link-grey -link" href="/tags/深度学习/">深度学习</a>
                </div>
            </div>
        </div>
        
        
        
    </div>
</div>



<div class="card">
    <div class="card-content">
        <h3 class="menu-label has-text-centered">Suka dengan artikel ini? Bantu penulis dengan donasi melalui</h3>
        <div class="buttons is-centered">
            
                
<a class="button is-info donate">
    <span class="icon is-small">
        <i class="fab fa-alipay"></i>
    </span>
    <span>Alipay</span>
    <div class="qrcode"><img src="/images/alipay.jpg" alt="Alipay"></div>
</a>

                
                
<a class="button is-success donate">
    <span class="icon is-small">
        <i class="fab fa-weixin"></i>
    </span>
    <span>Wechat</span>
    <div class="qrcode"><img src="/images/wechat.jpg" alt="Wechat"></div>
</a>

                
        </div>
    </div>
</div>



<div class="card card-transparent">
    <div class="level post-navigation is-flex-wrap is-mobile">
        
        <div class="level-start">
            <a class="level level-item has-link-grey  article-nav-prev" href="/2019/05/24/Note17-ConvBackProp-part4/">
                <i class="level-item fas fa-chevron-left"></i>
                <span class="level-item">代码实现二维平面上的卷积及其反向传播</span>
            </a>
        </div>
        
        
        <div class="level-end">
            <a class="level level-item has-link-grey  article-nav-next" href="/2019/05/24/Note15-ConvBackProp-part2/">
                <span class="level-item">步长stride为s的二维卷积方法的反向传播算法</span>
                <i class="level-item fas fa-chevron-right"></i>
            </a>
        </div>
        
    </div>
</div>



<div class="card">
    <div class="card-content">
        <h3 class="title is-5 has-text-weight-normal">Comentarios</h3>
        
<div id="valine-thread" class="content"></div>
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="//unpkg.com/valine/dist/Valine.min.js"></script>
<script>
    new Valine({
        el: '#valine-thread' ,
        notify: true,
        verify: false,
        app_id: 'iccwxYBr9y70NgcI4taslyB9-gzGzoHsz',
        app_key: 'ksGgGN0AeLXQQ1HfOy0mCrM0',
        placeholder: 'xxxxxxxx'
    });
</script>

    </div>
</div>

</div>
                




<div class="column is-4-tablet is-4-desktop is-3-widescreen  has-order-1 column-left ">
    
        
<div class="card widget">
    <div class="card-content">
        <nav class="level" style="margin-bottom:1rem">
            <div class="level-item has-text-centered">
                <div>
                    
                        <img class="image is-96x96 has-mb-6" src="/images/icon.jpg" alt="华轩">
                    
                    
                    <p class="is-size-4 is-block">
                        华轩
                    </p>
                    
                    
                    <p class="is-size-6 is-block">
                        A Student
                    </p>
                    
                    
                    <p class="is-size-6 is-flex is-flex-center has-text-grey">
                        <i class="fas fa-map-marker-alt has-mr-7"></i>
                        <span>Hangzhou Zhejiang, China</span>
                    </p>
                    
                </div>
            </div>
        </nav>
        <nav class="level menu-list is-mobile" style="margin-bottom:1rem">
            <div class="level-item has-text-centered is-marginless">
                <a href="/archives/">
                    <p class="heading">
                        Entradas
                    </p>
                    <p class="title has-text-weight-normal">
                        20
                    </p>
                </a>
            </div>
            <div class="level-item has-text-centered is-marginless">
                <a href="/categories/">
                    <p class="heading">
                        Categorias
                    </p>
                    <p class="title has-text-weight-normal">
                        3
                    </p>
                </a>
            </div>
            <div class="level-item has-text-centered is-marginless">
                <a href="/tags/">
                    <p class="heading">
                        Etiquetas
                    </p>
                    <p class="title has-text-weight-normal">
                        15
                    </p>
                </a>
            </div>
        </nav>
        <div class="level">
            <a class="level-item button is-link is-rounded" href="https://github.com/huaxuan0720" target="_blank">
                <i class="fab fa-github"></i>&nbsp;&nbsp;SEGUIR</a>
        </div>
        
        
        <div class="level is-mobile">
            
            <a class="level-item button is-white is-marginless" target="_blank" title="Github" href="https://github.com/huaxuan0720">
                
                <i class="fab fa-github"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank" title="Facebook" href="/">
                
                <i class="fab fa-facebook"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank" title="Twitter" href="/">
                
                <i class="fab fa-twitter"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank" title="RSS" href="/">
                
                <i class="fas fa-rss"></i>
                
            </a>
            
        </div>
        
    </div>
</div>

    
        
<div class="card widget column-left is-sticky" id="toc">
    <div class="card-content">
        <div class="menu">
            <h3 class="menu-label">
                Catálogo
            </h3>
            <ul class="menu-list"><li>
        <a class="is-flex" href="#前言">
        <span class="has-mr-6">1</span>
        <span>前言</span>
        </a></li><li>
        <a class="is-flex" href="#一、参数设置">
        <span class="has-mr-6">2</span>
        <span>一、参数设置</span>
        </a></li><li>
        <a class="is-flex" href="#二、误差传递">
        <span class="has-mr-6">3</span>
        <span>二、误差传递</span>
        </a></li><li>
        <a class="is-flex" href="#三、更新梯度">
        <span class="has-mr-6">4</span>
        <span>三、更新梯度</span>
        </a></li><li>
        <a class="is-flex" href="#四、总结">
        <span class="has-mr-6">5</span>
        <span>四、总结</span>
        </a></li></ul>
        </div>
    </div>
</div>


    
    
        <div class="column-right-shadow is-hidden-widescreen ">
        
        </div>
    
</div>

                
            </div>
        </div>
    </section>
    <footer class="footer">
    <div class="container">
        <div class="level">
            <div class="level-start has-text-centered-mobile">
                <a class="footer-logo is-block has-mb-6" href="/">
                
                    <img src="/images/favicon.svg" alt="步长stride为s的二维卷积方法的反向传播算法：一个十分极端的例子" height="28">
                
                </a>
                <p class="is-size-7">
                &copy; 2019 华轩&nbsp;
                Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> & <a href="http://github.com/ppoffice/hexo-theme-icarus" target="_blank">Icarus</a>
                
                <br>
                <span id="busuanzi_container_site_uv">
                Visited by <span id="busuanzi_value_site_uv">0</span> users
                </span>
                
                </p>
            </div>
            <div class="level-end">
            
                <div class="field has-addons is-flex-center-mobile has-mt-5-mobile is-flex-wrap is-flex-middle">
                
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" title="CC BY-NC-SA 4.0" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">
                        
                        <i class="fab fa-creative-commons"></i>&nbsp;<i class="fab fa-creative-commons-by"></i>&nbsp;<i class="fab fa-creative-commons-nc"></i>&nbsp;<i class="fab fa-creative-commons-sa"></i>&nbsp;
                        
                    </a>
                </p>
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" title="Xuan Hua&#39;s GitHub" href="https://www.github.com/huaxuan0720">
                        
                        <i class="fab fa-github"></i>&nbsp;
                        
                    </a>
                </p>
                
                </div>
            
            </div>
        </div>
    </div>
</footer>

    <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script>
<script>moment.locale("en");</script>


    
    
    
    <script src="/js/animation.js"></script>
    

    
    
    
    <script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script>
    <script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script>
    <script src="/js/gallery.js" defer></script>
    

    
    

<div id="outdated">
    <h6>Your browser is out-of-date!</h6>
    <p>Update your browser to view this website correctly. <a id="btnUpdateBrowser" href="http://outdatedbrowser.com/">Update
            my browser now </a></p>
    <p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">&times;</a></p>
</div>
<script src="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.js" defer></script>
<script>
    document.addEventListener("DOMContentLoaded", function () {
        outdatedBrowser({
            bgColor: '#f25648',
            color: '#ffffff',
            lowerThan: 'flex'
        });
    });
</script>


    
    
<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script>
<script>
document.addEventListener('DOMContentLoaded', function () {
    MathJax.Hub.Config({
        'HTML-CSS': {
            matchFontHeight: false
        },
        SVG: {
            matchFontHeight: false
        },
        CommonHTML: {
            matchFontHeight: false
        },
        tex2jax: {
            inlineMath: [
                ['$','$'],
                ['\\(','\\)']
            ]
        }
    });
});
</script>

    
    

<a id="back-to-top" title="Kembali ke atas" href="javascript:;">
    <i class="fas fa-chevron-up"></i>
</a>
<script src="/js/back-to-top.js" defer></script>


    
    

    
    
    
    

    
    
    
    
    
    <script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script>
    <script src="/js/clipboard.js" defer></script>
    

    
    
    

    


<script src="/js/main.js" defer></script>

    
    <div class="searchbox ins-search">
    <div class="searchbox-container ins-search-container">
        <div class="searchbox-input-wrapper">
            <input type="text" class="searchbox-input ins-search-input" placeholder="Type something...">
            <span class="searchbox-close ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="searchbox-result-wrapper ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
    (function (window) {
        var INSIGHT_CONFIG = {
            TRANSLATION: {
                POSTS: 'Entradas',
                PAGES: 'Pages',
                CATEGORIES: 'Categorias',
                TAGS: 'Etiquetas',
                UNTITLED: '(Untitled)',
            },
            CONTENT_URL: '/content.json',
        };
        window.INSIGHT_CONFIG = INSIGHT_CONFIG;
    })(window);
</script>
<script src="/js/insight.js" defer></script>
<link rel="stylesheet" href="/css/search.css">
<link rel="stylesheet" href="/css/insight.css">
    
</body>
</html>